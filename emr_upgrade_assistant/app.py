from quart import Quart, render_template, request, jsonify, Response, session
import os, sys
import json
import asyncio
from typing import Dict, Any
from dotenv import load_dotenv
import uuid
from datetime import datetime
import logging
from logging.handlers import RotatingFileHandler

# æ ¹æ®å®˜æ–¹æ–‡æ¡£å¯¼å…¥ Strands Agents å’Œ MCP ç›¸å…³æ¨¡å—
from mcp import stdio_client, StdioServerParameters
from strands import Agent
from strands.tools.mcp import MCPClient
from mem0_integration import create_mem0_integration
from mem0_tools import mem0_tools
from strands.models import BedrockModel

# åˆ›å»ºæ—¥å¿—ç›®å½•
log_dir = 'logs'
if not os.path.exists(log_dir):
    os.makedirs(log_dir)

# é…ç½®æ—¥å¿—è®°å½•å™¨
def setup_logger():
    logger = logging.getLogger('emr_assistant')
    logger.setLevel(logging.DEBUG)
    
    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨ï¼ˆå¸¦æ»šåŠ¨ï¼‰
    file_handler = RotatingFileHandler(
        filename=os.path.join(log_dir, 'emr_assistant.log'),
        maxBytes=100*1024*1024,  # 100MB
        backupCount=30,
        encoding='utf-8'
    )
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    return logger

# åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
logger = setup_logger()

load_dotenv()

app = Quart(__name__)
app.secret_key = os.getenv('SECRET_KEY', 'emr-upgrade-assistant-secret-key')

# ç¦ç”¨ Quart çš„ç¼“å†²ï¼Œç¡®ä¿æµå¼å“åº”ç«‹å³å‘é€
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.config['RESPONSE_TIMEOUT'] = 300  # å¢åŠ å“åº”è¶…æ—¶æ—¶é—´åˆ°300ç§’
app.config['BODY_TIMEOUT'] = 300  # å¢åŠ è¯·æ±‚ä½“è¶…æ—¶æ—¶é—´åˆ°300ç§’

class EMRUpgradeAssistant:
    """Amazon EMR ç‰ˆæœ¬å‡çº§åŠ©æ‰‹ - åŸºäº Strands Agents"""
    
    def __init__(self):
        try:
            # ä¸åœ¨åˆå§‹åŒ–æ—¶åˆ›å»º mem0 å®ä¾‹ï¼Œè€Œæ˜¯åœ¨æ¯æ¬¡è¯·æ±‚æ—¶åˆ›å»º
            self.mem0 = None
            
            logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ– EMR å‡çº§åŠ©æ‰‹...")
            
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£é…ç½® MCP å®¢æˆ·ç«¯
            # å‚è€ƒ: https://strandsagents.com/latest/user-guide/concepts/tools/mcp-tools/
            
            # è·å–é¡¹ç›®æ ¹ç›®å½•å’Œ MCP Server ç›®å½•
            project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
            mcp_server_dir = os.path.join(project_root, 'mcp_server')
            
            # åˆ›å»ºå¤šä¸ª MCP å®¢æˆ·ç«¯
            # 1. ä¸» MCP æœåŠ¡å™¨
            self.mcp_client = MCPClient(lambda: stdio_client(
                StdioServerParameters(
                    command="uv",
                    args=["--directory", mcp_server_dir, "run", "app.py"]
                )
            ))
            
            # 2. langgraph-crawler MCP æœåŠ¡å™¨ - ç”¨äºç½‘é¡µæœç´¢å’Œå†…å®¹æŠ“å–
            self.langgraph_crawler_client = MCPClient(lambda: stdio_client(
                StdioServerParameters(
                    command="npx",
                    args=["-y", "@langgraph-js/crawler-mcp@latest"]
                )
            ))
            
            logger.info("âœ… MCP å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            logger.debug(f"ğŸ“¡ MCP Server ç›®å½•: {mcp_server_dir}")
            
            # æ³¨æ„ï¼šæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼ŒAgent å¿…é¡»åœ¨ MCP å®¢æˆ·ç«¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­åˆ›å»ºå’Œä½¿ç”¨
            self.agent = None  # å°†åœ¨ process_query ä¸­åˆ›å»º
            
            logger.info("ğŸš€ EMR å‡çº§åŠ©æ‰‹ (Strands Agents) åˆå§‹åŒ–å®Œæˆ")
            
        except ImportError as e:
            logger.error(f"âŒ Strands Agents å¯¼å…¥å¤±è´¥: {str(e)}")
            logger.error("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£… Strands Agents:")
            logger.error("pip install strands-agents")
            logger.error("pip install strands-agents-tools")
            logger.error("pip install strands-agents-builder")
            self.agent = None
        except Exception as e:
            logger.error(f"âŒ Agent åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.agent = None
    
    def _get_instructions(self) -> str:
        """è·å– Agent æŒ‡ä»¤"""
        return """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Amazon EMR ç‰ˆæœ¬å‡çº§åŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯ï¼š

1. å¸®åŠ©ç”¨æˆ·äº†è§£ä¸åŒ EMR ç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚å’Œå‡çº§æ³¨æ„äº‹é¡¹
2. æä¾›å„ä¸ªç»„ä»¶ï¼ˆHiveã€Sparkã€Flinkã€HBaseç­‰ï¼‰çš„ç‰ˆæœ¬å…¼å®¹æ€§ä¿¡æ¯
3. è§£ç­”å‡çº§è¿‡ç¨‹ä¸­å¯èƒ½é‡åˆ°çš„æŠ€æœ¯é—®é¢˜
4. æä¾›æœ€ä½³å®è·µå»ºè®®

è¯·å§‹ç»ˆï¼š
- æä¾›å‡†ç¡®ã€è¯¦ç»†çš„æŠ€æœ¯ä¿¡æ¯
- åŸºäºçŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜
- ç»™å‡ºå…·ä½“çš„æ“ä½œå»ºè®®
- çªå‡ºé‡è¦çš„æ³¨æ„äº‹é¡¹å’Œé£é™©ç‚¹
- ä½¿ç”¨ä¸­æ–‡å›ç­”
- ç»“æ„åŒ–å›ç­”ï¼Œä½¿ç”¨æ ‡é¢˜å’Œè¦ç‚¹

å½“ç”¨æˆ·è¯¢é—® EMR å‡çº§ç›¸å…³é—®é¢˜æ—¶ï¼š
1. å¦‚æœéœ€è¦æœ€æ–°çš„ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨ mcp_langgraph_crawler_web_search_tool å·¥å…·æœç´¢äº’è”ç½‘ä¸Šçš„æœ€æ–°ä¿¡æ¯
2. å¦‚æœéœ€è¦æŸ¥çœ‹ç‰¹å®šç½‘é¡µçš„å†…å®¹ï¼Œè¯·ä½¿ç”¨ mcp_langgraph_crawler_crawl_tool å·¥å…·æŠ“å–ç½‘é¡µå†…å®¹
3. å¦‚æœéœ€è¦æœ¬åœ°çŸ¥è¯†åº“ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨ search_context å·¥å…·æ£€ç´¢ç›¸å…³ä¿¡æ¯

ç„¶ååŸºäºæ£€ç´¢ç»“æœæä¾›ä¸“ä¸šçš„å›ç­”ã€‚

å›ç­”æ ¼å¼å»ºè®®ï¼š
## é—®é¢˜åˆ†æ
## ä¸»è¦å»ºè®®
## å®æ–½æ­¥éª¤
## æ³¨æ„äº‹é¡¹
## ç›¸å…³æ–‡æ¡£
"""
    
    def _extract_content_from_chunk(self, chunk) -> str:
        """ä»æµå¼å“åº”å—ä¸­æå–å†…å®¹"""
        if hasattr(chunk, 'content'):
            return chunk.content
        elif hasattr(chunk, 'text'):
            return chunk.text
        elif isinstance(chunk, str):
            return chunk
        elif hasattr(chunk, 'delta') and hasattr(chunk.delta, 'content'):
            return chunk.delta.content
        elif hasattr(chunk, 'choices') and len(chunk.choices) > 0:
            # OpenAI æ ¼å¼
            choice = chunk.choices[0]
            if hasattr(choice, 'delta') and hasattr(choice.delta, 'content'):
                return choice.delta.content or ""
        else:
            # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            try:
                return str(chunk)
            except:
                return ""
    
    def _format_streaming_content(self, content: str) -> str:
        """æ ¼å¼åŒ–æµå¼å†…å®¹ï¼Œæ·»åŠ é€‚å½“çš„æ¢è¡Œ"""
        import re
        
        # å®šä¹‰éœ€è¦æ¢è¡Œçš„å…³é”®è¯å’Œæ¨¡å¼
        thinking_patterns = [
            r'è®©æˆ‘ä¸ºæ‚¨æ£€ç´¢',
            r'åŸºäºè·å–çš„ä¿¡æ¯',
            r'æˆ‘éœ€è¦è¿›ä¸€æ­¥äº†è§£',
            r'éœ€è¦æ›´å¤šå…³äº',
            r'è®©æˆ‘å†æŸ¥è¯¢',
            r'æ ¹æ®æ£€ç´¢ç»“æœ',
            r'## é—®é¢˜åˆ†æ',
            r'## ä¸»è¦å»ºè®®',
            r'## å®æ–½æ­¥éª¤',
            r'## æ³¨æ„äº‹é¡¹',
            r'## ç›¸å…³æ–‡æ¡£'
        ]
        
        # ä¸ºæ€è€ƒè¿‡ç¨‹æ·»åŠ æ¢è¡Œ
        formatted_content = content
        for pattern in thinking_patterns:
            # åœ¨åŒ¹é…çš„æ¨¡å¼å‰æ·»åŠ æ¢è¡Œï¼ˆå¦‚æœå‰é¢ä¸æ˜¯æ¢è¡Œçš„è¯ï¼‰
            formatted_content = re.sub(
                f'([^\\n])({pattern})', 
                r'\1\n\n\2', 
                formatted_content
            )
        
        # åœ¨å†’å·åæ·»åŠ æ¢è¡Œï¼ˆç”¨äº"å†…å®¹ï¼š"è¿™æ ·çš„æ¨¡å¼ï¼‰
        formatted_content = re.sub(r'ï¼š([^\\n])', r'ï¼š\n\1', formatted_content)
        
        return formatted_content
    
    def _stream_text_output(self, text):
        """å°†æ–‡æœ¬æŒ‰è¯è¯­æµå¼è¾“å‡º - ä¼˜åŒ–ç‰ˆæœ¬"""
        import re
        import time
        
        logger.debug(f"ğŸ“ å¼€å§‹æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œå†…å®¹é•¿åº¦: {len(text)}")
        
        # æŒ‰è¯è¯­å’Œæ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼Œä½†æ˜¯ä»¥æ›´å¤§çš„å—ä¸ºå•ä½
        # è¿™æ ·å¯ä»¥çœ‹åˆ°æµå¼æ•ˆæœï¼Œä½†ä¸ä¼šå¤ªæ…¢
        chunks = []
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+|\d+|[^\w\s]|\s+', text)
        
        # å°†å•è¯ç»„åˆæˆæ›´å¤§çš„å—ï¼ˆæ¯3-5ä¸ªè¯ä¸ºä¸€å—ï¼‰
        current_chunk = ""
        for i, word in enumerate(words):
            current_chunk += word
            
            # æ¯3-5ä¸ªè¯æˆ–é‡åˆ°å¥å·ã€æ¢è¡Œç¬¦æ—¶åˆ›å»ºä¸€ä¸ªå—
            if (i + 1) % 4 == 0 or word in ['.', 'ã€‚', '\n', '!', 'ï¼', '?', 'ï¼Ÿ']:
                if current_chunk.strip():
                    chunks.append(current_chunk)
                    current_chunk = ""
        
        # æ·»åŠ å‰©ä½™çš„å†…å®¹
        if current_chunk.strip():
            chunks.append(current_chunk)
        
        accumulated = ""
        
        for chunk in chunks:
            accumulated += chunk
            
            yield {
                "type": "content",
                "content": chunk,
                "accumulated": accumulated,
                "timestamp": datetime.now().isoformat()
            }
            
            # æ·»åŠ é€‚å½“çš„å»¶è¿Ÿæ¥æ¨¡æ‹Ÿæµå¼æ•ˆæœ
            time.sleep(0.1)  # 100ms å»¶è¿Ÿï¼Œè¶³å¤Ÿçœ‹åˆ°æµå¼æ•ˆæœä½†ä¸ä¼šå¤ªæ…¢
    


    
    def process_query_stream_simple(self, user_query: str, user_id: str = None):
        """
        ç®€åŒ–ç‰ˆæµå¼å¤„ç† - ç”¨äºè°ƒè¯•
        """
        try:
            logger.debug(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] å¼€å§‹å¤„ç†æŸ¥è¯¢: {user_query}")
            logger.debug(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] MCP Client çŠ¶æ€: {self.mcp_client is not None}")
            
            # ç›´æ¥è¿”å›ä¸€ä¸ªæµ‹è¯•å“åº”
            test_response = f"æ”¶åˆ°æ‚¨çš„é—®é¢˜ï¼š{user_query}\n\nè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å“åº”ï¼Œç”¨äºéªŒè¯æµå¼è¾“å‡ºæ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"
            
            logger.debug(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] å¼€å§‹æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œå†…å®¹é•¿åº¦: {len(test_response)}")
            
            # æ¨¡æ‹Ÿæµå¼è¾“å‡º
            chunk_count = 0
            for chunk in self._stream_text_output(test_response):
                chunk_count += 1
                print(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] ç”Ÿæˆç¬¬ {chunk_count} ä¸ªæ•°æ®å—: {chunk}")
                yield chunk
            
            logger.debug(f"âœ… [ç®€åŒ–ç‰ˆ] æµå¼è¾“å‡ºå®Œæˆï¼Œå…±ç”Ÿæˆ {chunk_count} ä¸ªæ•°æ®å—")
                
        except Exception as e:
            print(f"âŒ [ç®€åŒ–ç‰ˆ] å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            print(f"âŒ [ç®€åŒ–ç‰ˆ] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            yield {
                "type": "error",
                "error": f"ç®€åŒ–ç‰ˆå¤„ç†å¤±è´¥: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

    async def process_query_stream(self, user_query: str, user_id: str = None):
        """
        æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - ä½¿ç”¨ Strands Agent çœŸæ­£çš„æµå¼å“åº”
        ä¿è¯ LLM å†…å®¹å’Œ MCP Server å·¥å…·å†…å®¹éƒ½èƒ½æµå¼è¿”å›åˆ°é¡µé¢ï¼Œå¹¶åœ¨åå°æ‰“å°ã€‚
        """
        if not self.mcp_client:
            yield {
                "type": "error",
                "error": "MCP å®¢æˆ·ç«¯æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥å®‰è£…å’Œé…ç½®",
                "timestamp": datetime.now().isoformat()
            }
            return

        try:
            logger.debug(f"ğŸ“ å¼€å§‹æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢: {user_query}")
            
            # è·å–ä¸»MCPæœåŠ¡å™¨çš„å·¥å…·
            with self.mcp_client:
                mcp_tools = self.mcp_client.list_tools_sync()
                logger.debug(f"ğŸ”§ è·å–åˆ° {len(mcp_tools)} ä¸ªä¸»MCPå·¥å…·")
            
            # è·å–langgraph-crawler MCPæœåŠ¡å™¨çš„å·¥å…·
            crawler_tools = []
            try:
                with self.langgraph_crawler_client:
                    crawler_tools = self.langgraph_crawler_client.list_tools_sync()
                    logger.debug(f"ğŸ”§ è·å–åˆ° {len(crawler_tools)} ä¸ªlanggraph-crawlerå·¥å…·")
            except Exception as crawler_error:
                logger.error(f"âš ï¸ è·å–langgraph-crawlerå·¥å…·å¤±è´¥: {str(crawler_error)}")
            
            # åˆå¹¶æ‰€æœ‰å·¥å…·
            all_tools = mcp_tools + mem0_tools + crawler_tools
            logger.debug(f"ğŸ”§ æ€»å…±è·å–åˆ° {len(all_tools)} ä¸ªå·¥å…·: {len(mcp_tools)}ä¸ªä¸»MCPå·¥å…· + {len(mem0_tools)}ä¸ªmem0å·¥å…· + {len(crawler_tools)}ä¸ªcrawlerå·¥å…·")
            
            # ä½¿ç”¨ä¸»MCPå®¢æˆ·ç«¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            with self.mcp_client:
                try:
                    bedrock_model = BedrockModel(
                        model_id="us.anthropic.claude-sonnet-4-20250514-v1:0",
                        region_name="us-east-1",
                        temperature=0.3,
                    )
                    agent = Agent(
                        tools=all_tools,
                        callback_handler=None
                    )
                    logger.debug("âœ… æˆåŠŸåˆ›å»ºä½¿ç”¨ Agent")
                except Exception as model_error:
                    logger.error(f"âš ï¸ ä½¿ç”¨ Claude 4.0 Sonnet åˆ›å»º Agent å¤±è´¥: {str(model_error)}")
                    logger.error("å°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹åˆ›å»º Agent")
                    agent = Agent(tools=all_tools, callback_handler=None)
                if hasattr(agent, 'model') and hasattr(agent.model, 'config'):
                    logger.debug(f"ğŸ”§ ä½¿ç”¨æ¨¡å‹é…ç½®: {agent.model.config}")
                else:
                    logger.warn("âš ï¸ æ— æ³•è·å–æ¨¡å‹é…ç½®ä¿¡æ¯")
                user_mem0 = create_mem0_integration(user_id)
                from mem0_tools import set_current_user_mem0
                set_current_user_mem0(user_mem0)
                historical_context = user_mem0.get_context_for_query(user_query)
                system_instructions = self._get_instructions()
                if historical_context:
                    full_query = f"{system_instructions}\n\n{historical_context}\n\nç”¨æˆ·é—®é¢˜: {user_query}"
                    logger.debug(f"ğŸ“š æ·»åŠ äº†å†å²ä¸Šä¸‹æ–‡ï¼Œé•¿åº¦: {len(historical_context)}")
                else:
                    full_query = f"{system_instructions}\n\nç”¨æˆ·é—®é¢˜: {user_query}"
                logger.debug(f"ğŸ”§ å¼€å§‹ Strands Agent æµå¼è°ƒç”¨...")
                accumulated_response = ""
                async def async_stream():
                    nonlocal accumulated_response
                    try:
                        # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
                        timeout_seconds = 240  # å¢åŠ åˆ°240ç§’
                        
                        # è·å–æµå¼å“åº”è¿­ä»£å™¨
                        stream_iterator = agent.stream_async(full_query)
                        
                        # åˆå§‹åŒ–å¿ƒè·³è®¡æ•°å™¨
                        heartbeat_counter = 0
                        last_heartbeat_time = datetime.now()
                        
                        # å¤„ç†æµå¼å“åº”
                        while True:
                            # æ¯5ç§’å‘é€ä¸€æ¬¡å¿ƒè·³ï¼Œä¿æŒè¿æ¥æ´»è·ƒ
                            current_time = datetime.now()
                            if (current_time - last_heartbeat_time).total_seconds() >= 5:
                                yield {
                                    "type": "heartbeat",
                                    "timestamp": current_time.isoformat()
                                }
                                last_heartbeat_time = current_time
                                heartbeat_counter += 1
                            
                            # ç­‰å¾…æµå¼å“åº”æˆ–è¶…æ—¶
                            try:
                                # ä½¿ç”¨asyncio.wait_forè®¾ç½®è¶…æ—¶ï¼Œä½†å¢åŠ è¶…æ—¶æ—¶é—´
                                event = await asyncio.wait_for(stream_iterator.__anext__(), timeout=10.0)
                                
                                # å¤„ç†äº‹ä»¶
                                # LLM å†…å®¹æµå¼è¿”å›
                                if "data" in event:
                                    content = event["data"]
                                    if content:
                                        accumulated_response += content
                                        logger.debug(f"ğŸ“ LLMæµå¼å†…å®¹: {content}")
                                        yield {
                                            "type": "content",
                                            "content": content,
                                            "accumulated": accumulated_response,
                                            "timestamp": datetime.now().isoformat()
                                        }
                                
                                # å·¥å…·è°ƒç”¨äº‹ä»¶
                                if "current_tool_use" in event and event["current_tool_use"].get("name"):
                                    tool_name = event["current_tool_use"]["name"]
                                    tool_input = event["current_tool_use"].get("input", {})
                                    logger.debug(f"ğŸ”§ å·¥å…·è°ƒç”¨: {tool_name}, è¾“å…¥: {tool_input}")
                                    
                                    # å¯¹ç½‘ç»œæœç´¢å·¥å…·æ·»åŠ ç‰¹æ®Šå¤„ç†
                                    if "web_search" in tool_name.lower() or "crawl" in tool_name.lower():
                                        yield {
                                            "type": "status",
                                            "message": f"[æ­£åœ¨æœç´¢ç½‘ç»œä¿¡æ¯: {tool_input.get('query', '')}]",
                                            "timestamp": datetime.now().isoformat()
                                        }
                                    else:
                                        yield {
                                            "type": "status",
                                            "message": f"[ä½¿ç”¨å·¥å…·: {tool_name}]",
                                            "timestamp": datetime.now().isoformat()
                                        }
                                
                                # MCP Server å·¥å…·è¿”å›å†…å®¹
                                if "tool_response" in event and event["tool_response"]:
                                    tool_name = event.get("current_tool_use", {}).get("name", "æœªçŸ¥å·¥å…·")
                                    logger.debug(f"ğŸŸ¢ å·¥å…· {tool_name} è¿”å›ç»“æœ")
                                    
                                    # å¯¹äºç½‘ç»œæœç´¢å·¥å…·ï¼Œé€šçŸ¥å‰ç«¯æœç´¢å®Œæˆ
                                    if "web_search" in tool_name.lower() or "crawl" in tool_name.lower():
                                        yield {
                                            "type": "status",
                                            "message": f"[ç½‘ç»œæœç´¢å®Œæˆï¼Œæ­£åœ¨åˆ†æç»“æœ]",
                                            "timestamp": datetime.now().isoformat()
                                        }
                                
                            except StopAsyncIteration:
                                # æµç»“æŸ
                                logger.debug("âœ… æµå¼å“åº”å®Œæˆ")
                                break
                                
                            except asyncio.TimeoutError:
                                # è¶…æ—¶ä½†ä¸ä¸­æ–­æµç¨‹ï¼Œç»§ç»­ç­‰å¾…
                                logger.debug(f"â±ï¸ ç­‰å¾…æµå¼å“åº”ä¸­... ({heartbeat_counter * 10}ç§’)")
                                
                                # å¦‚æœè¶…è¿‡æ€»è¶…æ—¶æ—¶é—´ï¼Œå‘é€çŠ¶æ€æ¶ˆæ¯ä½†ä¸ä¸­æ–­
                                if heartbeat_counter * 10 > timeout_seconds:
                                    logger.warning(f"âš ï¸ æµå¼å“åº”å¤„ç†æ—¶é—´è¾ƒé•¿ ({timeout_seconds}ç§’)")
                                    yield {
                                        "type": "status",
                                        "message": f"[å¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œå¯èƒ½æ˜¯ç½‘ç»œæœç´¢æˆ–åˆ†æå¤æ‚é—®é¢˜å¯¼è‡´ï¼Œè¯·è€å¿ƒç­‰å¾…...]",
                                        "timestamp": datetime.now().isoformat()
                                    }
                            
                            except Exception as event_error:
                                # å¤„ç†å•ä¸ªäº‹ä»¶çš„é”™è¯¯ï¼Œä½†ä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                                logger.error(f"âŒ å¤„ç†äº‹ä»¶æ—¶å‡ºé”™: {str(event_error)}")
                                yield {
                                    "type": "status",
                                    "message": f"[å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œä½†ä»åœ¨ç»§ç»­...]",
                                    "timestamp": datetime.now().isoformat()
                                }
                    except Exception as e:
                        logger.error(f"âŒ å¼‚æ­¥æµå¼è°ƒç”¨å¤±è´¥: {str(e)}")
                        import traceback
                        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                        yield {
                            "type": "error",
                            "error": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
                            "timestamp": datetime.now().isoformat()
                        }
                async for chunk in async_stream():
                    yield chunk
                if accumulated_response:
                    try:
                        user_mem0.add_memory(
                            message="EMRå‡çº§å’¨è¯¢å¯¹è¯",
                            user_query=user_query,
                            response=accumulated_response,
                            metadata={
                                "user_id": user_id,
                                "response_length": len(accumulated_response)
                            }
                        )
                        logger.debug(f"ğŸ’¾ å¯¹è¯è®°å¿†å·²ä¿å­˜åˆ° mem0 {user_id}")
                    except Exception as mem_error:
                        logger.error(f"âš ï¸ ä¿å­˜è®°å¿†å¤±è´¥: {str(mem_error)}")
        except Exception as e:
            logger.error(f"âŒ æµå¼å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")
            yield {
                "type": "error",
                "error": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

    async def process_query(self, user_query: str, user_id: str = None) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢å†…å®¹
            user_id: ç”¨æˆ·ID
            
        Returns:
            åŒ…å«å›ç­”å’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
        """
        if not self.mcp_client:
            return {
                "success": False,
                "error": "MCP å®¢æˆ·ç«¯æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥å®‰è£…å’Œé…ç½®",
                "timestamp": datetime.now().isoformat()
            }
        
        try:
            logger.info(f"ğŸ“ å¤„ç†ç”¨æˆ·æŸ¥è¯¢: {user_query}")
            
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå¿…é¡»åœ¨ MCP å®¢æˆ·ç«¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­ä½¿ç”¨ Agent
            with self.mcp_client:
                # è·å– MCP æœåŠ¡å™¨æä¾›çš„å·¥å…·
                tools = self.mcp_client.list_tools_sync()
                logger.debug(f"ğŸ”§ è·å–åˆ° {len(tools)} ä¸ª MCP å·¥å…·")
                
                # åœ¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­åˆ›å»º Agent
                # æ ¹æ® Strands Agents APIï¼ŒAgent åˆå§‹åŒ–ä¸æ¥å— instructions å‚æ•°
                agent = Agent(tools=tools)
                
                # æ„å»ºåŒ…å«ç³»ç»ŸæŒ‡ä»¤çš„å®Œæ•´æŸ¥è¯¢
                system_instructions = self._get_instructions()
                full_query = f"{system_instructions}\n\nç”¨æˆ·é—®é¢˜: {user_query}"
                
                # ä½¿ç”¨ Agent å¤„ç†æŸ¥è¯¢
                response = agent(full_query)
                
                logger.debug("âœ… Strands Agent å¤„ç†å®Œæˆ")
                
                # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå“åº”æ ¼å¼å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡
                if isinstance(response, str):
                    answer = response
                    tools_used = []
                else:
                    answer = getattr(response, 'content', str(response))
                    tools_used = getattr(response, 'tools_used', [])
                
                return {
                    "success": True,
                    "answer": answer,
                    "tools_used": tools_used,
                    "query": user_query,
                    "timestamp": datetime.now().isoformat()
                }
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")
            return {
                "success": False,
                "error": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

# åˆå§‹åŒ–åŠ©æ‰‹
emr_assistant = EMRUpgradeAssistant()

@app.route('/')
async def index():
    """ä¸»é¡µ - ç”Ÿæˆå¹¶å­˜å‚¨ç”¨æˆ·ID"""
    # æ£€æŸ¥ä¼šè¯ä¸­æ˜¯å¦å·²æœ‰ç”¨æˆ·IDï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
    if 'user_id' not in session:
        session['user_id'] = str(uuid.uuid4())
        logger.info(f"åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {session['user_id']}")
    else:
        logger.info(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {session['user_id']}")
    
    return await render_template('index.html')

@app.route('/chat', methods=['POST'])
async def chat_stream():
    """å¤„ç†èŠå¤©è¯·æ±‚ - æµå¼å“åº”"""
    try:
        data = await request.get_json()
        user_query = data.get('query', '').strip()
        
        if not user_query:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥æ‚¨çš„é—®é¢˜'
            }), 400
        
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨èŠå¤©è¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # è¿”å›æµå¼å“åº” - å¼ºåˆ¶å®æ—¶ä¼ è¾“ï¼Œæ·»åŠ å¡«å……æ•°æ®
        async def generate_stream():
            import sys
            import os
            
            # å¼ºåˆ¶ç¦ç”¨ Python çš„è¾“å‡ºç¼“å†²
            os.environ['PYTHONUNBUFFERED'] = '1'
            
            try:
                logger.debug("ğŸ”„ å¼€å§‹ç”Ÿæˆæµå¼å“åº”...")
                
                # ç«‹å³å‘é€å¿ƒè·³å’Œå¡«å……æ•°æ®ï¼Œå¼ºåˆ¶å»ºç«‹è¿æ¥
                heartbeat = json.dumps({'type': 'heartbeat'})
                yield f"data: {heartbeat}\n\n"
                
                # å‘é€å¡«å……æ•°æ®ï¼Œå¼ºåˆ¶ Flask ç«‹å³å‘é€å“åº”å¤´
                padding = " " * 1024  # 1KB å¡«å……æ•°æ®
                yield f": padding {padding}\n\n"
                
                logger.debug("ğŸ“¡ å¿ƒè·³å’Œå¡«å……æ•°æ®å·²å‘é€ï¼Œå¼€å§‹å¤„ç†æŸ¥è¯¢...")
                
                # å…ˆå‘é€ä¸€ä¸ªåˆå§‹å†…å®¹ï¼Œç¡®ä¿å‰ç«¯èƒ½ç«‹å³æ˜¾ç¤º
                initial_content = {
                    "type": "content",
                    "content": "æ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜...\n\n",
                    "accumulated": "æ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜...\n\n",
                    "timestamp": datetime.now().isoformat()
                }
                yield f"data: {json.dumps(initial_content, ensure_ascii=False)}\n\n"
                yield f": initial-content\n\n"
                
                # ä½¿ç”¨å®Œæ•´çš„ Strands Agent æµå¼å¤„ç†
                chunk_count = 0
                async for chunk in emr_assistant.process_query_stream(user_query, user_id):
                    chunk_count += 1
                    logger.debug(f"ç”Ÿæˆç¬¬ {chunk_count} ä¸ªæ•°æ®å—: {chunk}")
                    
                    # ç¡®ä¿ JSON åºåˆ—åŒ–ä¸ä¼šå¤±è´¥
                    try:
                        chunk_data = json.dumps(chunk, ensure_ascii=False)
                    except Exception as json_err:
                        print(f"JSON åºåˆ—åŒ–å¤±è´¥: {str(json_err)}, å°è¯•ç®€åŒ–æ•°æ®")
                        # å¦‚æœåºåˆ—åŒ–å¤±è´¥ï¼Œå°è¯•ç®€åŒ–æ•°æ®
                        simplified_chunk = {
                            "type": chunk.get("type", "content"),
                            "content": str(chunk.get("content", "")),
                            "timestamp": datetime.now().isoformat()
                        }
                        chunk_data = json.dumps(simplified_chunk, ensure_ascii=False)
                    
                    # ç«‹å³å‘é€æ•°æ®ï¼Œç¡®ä¿æ¯ä¸ªå—éƒ½æœ‰å®Œæ•´çš„ SSE æ ¼å¼
                    yield f"data: {chunk_data}\n\n"
                    
                    # æ·»åŠ å°çš„å¡«å……æ•°æ®ç¡®ä¿ç«‹å³ä¼ è¾“
                    yield f": chunk-{chunk_count}\n\n"
                    
                    # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
                    sys.stdout.flush()
                    sys.stderr.flush()
                
                # å‘é€ç»“æŸä¿¡å·
                end_data = json.dumps({'type': 'end'})
                yield f"data: {end_data}\n\n"
                
                print(f"âœ… æµå¼å“åº”å®Œæˆï¼Œå…±å‘é€ {chunk_count} ä¸ªæ•°æ®å—")
                
            except Exception as e:
                import traceback
                logger.error(f"âŒ æµå¼å“åº”é”™è¯¯: {str(e)}")
                print(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                error_data = json.dumps({'type': 'error', 'error': str(e)})
                yield f"data: {error_data}\n\n"
        
        return Response(
            generate_stream(), 
            content_type='text/event-stream',
            headers={
                'Cache-Control': 'no-cache, no-store, must-revalidate',
                'Connection': 'keep-alive',
                'X-Accel-Buffering': 'no',  # ç¦ç”¨Nginxç¼“å†²
                'Transfer-Encoding': 'chunked'  # ä½¿ç”¨åˆ†å—ä¼ è¾“ç¼–ç 
            }
        )
        
    except Exception as e:
        import traceback
        logger.error(f"âŒ å¤„ç†èŠå¤©è¯·æ±‚å¤±è´¥: {str(e)}")
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        return jsonify({
            'success': False,
            'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/chat-sync', methods=['POST'])
async def chat_sync():
    """å¤„ç†èŠå¤©è¯·æ±‚ - åŒæ­¥å“åº”ï¼ˆå¤‡ç”¨ï¼‰"""
    try:
        data = await request.get_json()
        user_query = data.get('query', '').strip()
        
        if not user_query:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥æ‚¨çš„é—®é¢˜'
            }), 400
        
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨chat-syncè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # å¤„ç†æŸ¥è¯¢
        result = await emr_assistant.process_query(user_query, user_id)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/memory/stats')
async def memory_stats():
    """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
    try:
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨memory/statsè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        stats = user_mem0.get_memory_stats()
        
        return jsonify({
            'success': True,
            'stats': stats,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–è®°å¿†ç»Ÿè®¡å¤±è´¥: {str(e)}'
        }), 500

@app.route('/memory/search', methods=['POST'])
async def search_memories():
    """æœç´¢å†å²è®°å¿†"""
    try:
        data = await request.get_json()
        query = data.get('query', '').strip()
        limit = data.get('limit', 5)
        
        if not query:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥æœç´¢æŸ¥è¯¢'
            }), 400
        
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨memory/searchè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        memories = user_mem0.search_memories(query, limit)
        
        return jsonify({
            'success': True,
            'memories': memories,
            'query': query,
            'count': len(memories),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æœç´¢è®°å¿†å¤±è´¥: {str(e)}'
        }), 500

@app.route('/memory/recent')
async def get_recent_memories():
    """è·å–æœ€è¿‘çš„è®°å¿†"""
    try:
        limit = int(request.args.get('limit', 10))
        
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨memory/recentè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        memories = user_mem0.get_recent_memories(limit)
        
        return jsonify({
            'success': True,
            'memories': memories,
            'count': len(memories),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–æœ€è¿‘è®°å¿†å¤±è´¥: {str(e)}'
        }), 500

@app.route('/memory/clear', methods=['POST'])
async def clear_memories():
    """æ¸…é™¤æ‰€æœ‰è®°å¿†"""
    try:
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨memory/clearè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        success = user_mem0.clear_user_memories()
        
        if success:
            return jsonify({
                'success': True,
                'message': 'æ‰€æœ‰è®°å¿†å·²æˆåŠŸæ¸…é™¤',
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'success': False,
                'error': 'æ¸…é™¤è®°å¿†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®'
            }), 500
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æ¸…é™¤è®°å¿†å¤±è´¥: {str(e)}'
        }), 500

# æµ‹è¯•æµå¼å“åº”è·¯ç”±å·²ç§»é™¤

@app.route('/health')
async def health():
    """å¥åº·æ£€æŸ¥"""
    try:
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ mem0 å®ä¾‹æ¥æ£€æŸ¥çŠ¶æ€
        temp_mem0 = create_mem0_integration()
        mem0_enabled = temp_mem0.enabled
    except:
        mem0_enabled = False
    
    return jsonify({
        'status': 'healthy',
        'service': 'EMR Upgrade Assistant',
        'mem0_enabled': mem0_enabled,
        'timestamp': datetime.now().isoformat()
    })

@app.errorhandler(404)
async def not_found(error):
    return jsonify({'error': 'Not found'}), 404

@app.errorhandler(500)
async def internal_error(error):
    return jsonify({'error': 'Internal server error'}), 500

# å¯åŠ¨æ–¹å¼æç¤º
if __name__ == '__main__':
    logger.info('è¯·ä½¿ç”¨ hypercorn å¯åŠ¨æ­¤åº”ç”¨ï¼Œä¾‹å¦‚:')
    logger.info('hypercorn emr_upgrade_assistant.app:app --bind 0.0.0.0:5001')