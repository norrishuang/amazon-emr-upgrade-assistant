# åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ç¦ç”¨ OpenTelemetry
import os
os.environ["OTEL_SDK_DISABLED"] = "true"
os.environ["OTEL_PYTHON_DISABLED"] = "true"

from quart import Quart, render_template, request, jsonify, Response, session
import sys
import json
import asyncio
from typing import Dict, Any
from dotenv import load_dotenv
import uuid
from datetime import datetime
import logging
from logging.handlers import RotatingFileHandler

# æ ¹æ®å®˜æ–¹æ–‡æ¡£å¯¼å…¥ Strands Agents å’Œ MCP ç›¸å…³æ¨¡å—
from mcp import stdio_client, StdioServerParameters
from strands import Agent
from strands.session.file_session_manager import FileSessionManager
from strands.tools.mcp import MCPClient
from mem0_integration import create_mem0_integration
from mem0_tools import mem0_tools
from strands.models import BedrockModel

# åˆ›å»ºæ—¥å¿—ç›®å½•
log_dir = 'logs'
if not os.path.exists(log_dir):
    os.makedirs(log_dir)

# é…ç½®æ—¥å¿—è®°å½•å™¨
def setup_logger():
    logger = logging.getLogger('emr_assistant')
    
    # å¦‚æœloggerå·²ç»æœ‰handlersï¼Œè¯´æ˜å·²ç»åˆå§‹åŒ–è¿‡äº†ï¼Œç›´æ¥è¿”å›
    if logger.handlers:
        return logger
        
    logger.setLevel(logging.INFO)
    # é˜²æ­¢æ—¥å¿—ä¼ æ’­åˆ°æ ¹loggerï¼Œé¿å…é‡å¤è¾“å‡º
    logger.propagate = False
    
    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨ï¼ˆå¸¦æ»šåŠ¨ï¼‰
    file_handler = RotatingFileHandler(
        filename=os.path.join(log_dir, 'emr_assistant.log'),
        maxBytes=100*1024*1024,  # 100MB
        backupCount=30,
        encoding='utf-8'
    )
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    return logger

# åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
logger = setup_logger()

# å°è¯•å¯¼å…¥ä¼šè¯ç®¡ç†æ¨¡å—ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨å…¼å®¹æ¨¡å¼
try:
    from strands.session.file_session_manager import FileSessionManager
    SESSION_MANAGEMENT_AVAILABLE = True
    logger.info("âœ… Strands ä¼šè¯ç®¡ç†åŠŸèƒ½å¯ç”¨")
except ImportError as import_error:
    SESSION_MANAGEMENT_AVAILABLE = False
    import traceback
    error_stack = traceback.format_exc()
    logger.error(f"âš ï¸ Strands ä¼šè¯ç®¡ç†åŠŸèƒ½å¯¼å…¥å¤±è´¥: {str(import_error)}")
    logger.error(f"è¯¦ç»†é”™è¯¯å †æ ˆ:\n{error_stack}")
    logger.warning("âš ï¸ å°†ä½¿ç”¨å…¼å®¹æ¨¡å¼è¿è¡Œï¼Œæ²¡æœ‰ä¼šè¯ç®¡ç†åŠŸèƒ½")
    
    # åˆ›å»ºä¸€ä¸ªç©ºçš„ FileSessionManager ç±»ä½œä¸ºå ä½ç¬¦
    class FileSessionManager:
        def __init__(self, session_id=None, storage_dir=None):
            self.session_id = session_id
            self.storage_dir = storage_dir
            logger.debug(f"åˆ›å»ºå…¼å®¹æ¨¡å¼ä¼šè¯ç®¡ç†å™¨: session_id={session_id}, storage_dir={storage_dir}")



load_dotenv()

app = Quart(__name__)
app.secret_key = os.getenv('SECRET_KEY', 'emr-upgrade-assistant-secret-key')

# ç¦ç”¨ Quart çš„ç¼“å†²ï¼Œç¡®ä¿æµå¼å“åº”ç«‹å³å‘é€
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.config['RESPONSE_TIMEOUT'] = 300  # å¢åŠ å“åº”è¶…æ—¶æ—¶é—´åˆ°300ç§’
app.config['BODY_TIMEOUT'] = 300  # å¢åŠ è¯·æ±‚ä½“è¶…æ—¶æ—¶é—´åˆ°300ç§’

class EMRUpgradeAssistant:
    """Amazon EMR ç‰ˆæœ¬å‡çº§åŠ©æ‰‹ - åŸºäº Strands Agents"""
    
    def __init__(self):
        try:
            # ä¸åœ¨åˆå§‹åŒ–æ—¶åˆ›å»º mem0 å®ä¾‹ï¼Œè€Œæ˜¯åœ¨æ¯æ¬¡è¯·æ±‚æ—¶åˆ›å»º
            self.mem0 = None
            
            logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ– EMR å‡çº§åŠ©æ‰‹...")

            self.bedrock_region = os.getenv('BEDROCK_REGION', 'us-east-1')
            self.bedorck_model = os.getenv('BEDROCK_MODEL_ID', 'us-east-1')
            
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£é…ç½® MCP å®¢æˆ·ç«¯
            # å‚è€ƒ: https://strandsagents.com/latest/user-guide/concepts/tools/mcp-tools/
            
            # è·å–é¡¹ç›®æ ¹ç›®å½•å’Œ MCP Server ç›®å½•
            project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
            mcp_server_dir = os.path.join(project_root, 'mcp_server')
            
            # åˆ›å»ºä¼šè¯ç›®å½•ç”¨äºå­˜å‚¨ Strands ä¼šè¯æ•°æ®ï¼ˆå¦‚æœä¼šè¯ç®¡ç†å¯ç”¨ï¼‰
            self.sessions_dir = os.path.join(project_root, 'sessions')
            if SESSION_MANAGEMENT_AVAILABLE:
                if not os.path.exists(self.sessions_dir):
                    os.makedirs(self.sessions_dir)
                    logger.info(f"âœ… åˆ›å»ºä¼šè¯ç›®å½•: {self.sessions_dir}")
            else:
                logger.info("âš ï¸ ä¼šè¯ç®¡ç†ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å…¼å®¹æ¨¡å¼")
            
            # åˆ›å»ºå¤šä¸ª MCP å®¢æˆ·ç«¯
            # 1. ä¸» MCP æœåŠ¡å™¨
            self.mcp_client = MCPClient(lambda: stdio_client(
                StdioServerParameters(
                    command="uv",
                    args=["--directory", mcp_server_dir, "run", "app.py"]
                )
            ))
            
            # 2. langgraph-crawler MCP æœåŠ¡å™¨ - ç”¨äºç½‘é¡µæœç´¢å’Œå†…å®¹æŠ“å–
            self.langgraph_crawler_client = MCPClient(lambda: stdio_client(
                StdioServerParameters(
                    command="npx",
                    args=["-y", "@langgraph-js/crawler-mcp@latest"]
                )
            ))
            
            # 3. AWS Documentation MCP æœåŠ¡å™¨ - ç”¨äºæŸ¥è¯¢ AWS æ–‡æ¡£
            self.aws_docs_client = MCPClient(lambda: stdio_client(
                StdioServerParameters(
                    command="uvx",
                    args=["awslabs.aws-documentation-mcp-server@latest"],
                    env={
                        "FASTMCP_LOG_LEVEL": "ERROR",
                        "AWS_DOCUMENTATION_PARTITION": "aws"
                    }
                )
            ))
            
            logger.info("âœ… MCP å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            logger.debug(f"ğŸ“¡ MCP Server ç›®å½•: {mcp_server_dir}")
            
            # æ³¨æ„ï¼šæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼ŒAgent å¿…é¡»åœ¨ MCP å®¢æˆ·ç«¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­åˆ›å»ºå’Œä½¿ç”¨
            self.agent = None  # å°†åœ¨ process_query ä¸­åˆ›å»º
            
            logger.info("ğŸš€ EMR å‡çº§åŠ©æ‰‹ (Strands Agents) åˆå§‹åŒ–å®Œæˆ")
            
        except ImportError as e:
            logger.error(f"âŒ Strands Agents å¯¼å…¥å¤±è´¥: {str(e)}")
            logger.error("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£… Strands Agents:")
            logger.error("pip install strands-agents")
            logger.error("pip install strands-agents-tools")
            logger.error("pip install strands-agents-builder")
            self.agent = None
        except Exception as e:
            logger.error(f"âŒ Agent åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.agent = None
    
    def _get_instructions(self) -> str:
        """è·å– Agent æŒ‡ä»¤"""
        return """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Amazon EMR ç‰ˆæœ¬å‡çº§åŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯ï¼š

1. å¸®åŠ©ç”¨æˆ·äº†è§£ä¸åŒ EMR ç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚å’Œå‡çº§æ³¨æ„äº‹é¡¹
2. æä¾›å„ä¸ªç»„ä»¶ï¼ˆHiveã€Sparkã€Flinkã€HBaseç­‰ï¼‰çš„ç‰ˆæœ¬å…¼å®¹æ€§ä¿¡æ¯
3. è§£ç­”å‡çº§è¿‡ç¨‹ä¸­å¯èƒ½é‡åˆ°çš„æŠ€æœ¯é—®é¢˜
4. æä¾›æœ€ä½³å®è·µå»ºè®®

è¯·å§‹ç»ˆï¼š
- æä¾›å‡†ç¡®ã€è¯¦ç»†çš„æŠ€æœ¯ä¿¡æ¯
- åŸºäºçŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜
- ç»™å‡ºå…·ä½“çš„æ“ä½œå»ºè®®
- çªå‡ºé‡è¦çš„æ³¨æ„äº‹é¡¹å’Œé£é™©ç‚¹
- ä½¿ç”¨ä¸­æ–‡å›ç­”
- ç»“æ„åŒ–å›ç­”ï¼Œä½¿ç”¨æ ‡é¢˜å’Œè¦ç‚¹
- åˆ©ç”¨ä½ çš„ä¼šè¯è®°å¿†ï¼Œè®°ä½ç”¨æˆ·ä¹‹å‰åœ¨æœ¬æ¬¡å¯¹è¯ä¸­æåˆ°çš„ä¿¡æ¯ï¼Œä¿æŒå¯¹è¯è¿è´¯æ€§

å½“ç”¨æˆ·è¯¢é—® EMR å‡çº§ç›¸å…³é—®é¢˜æ—¶ï¼š
1. å¦‚æœéœ€è¦æœ€æ–°çš„ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨ mcp_langgraph_crawler_web_search_tool å·¥å…·æœç´¢äº’è”ç½‘ä¸Šçš„æœ€æ–°ä¿¡æ¯
2. å¦‚æœéœ€è¦æŸ¥çœ‹ç‰¹å®šç½‘é¡µçš„å†…å®¹ï¼Œè¯·ä½¿ç”¨ mcp_langgraph_crawler_crawl_tool å·¥å…·æŠ“å–è·Ÿ Apache ç¤¾åŒºå®˜æ–¹ç›¸å…³çš„ç½‘é¡µå†…å®¹ï¼ŒåŒ…æ‹¬ä¸é™äº [hive/spark/flink/hbase/hadoop/sqoop/tez/iceberg].apache.org issues.apache.orgï¼Œstackoverflow.com
3. å¦‚æœéœ€è¦æŸ¥è¯¢ AWS å®˜æ–¹æ–‡æ¡£ï¼Œè¯·ä½¿ç”¨ AWS æ–‡æ¡£å·¥å…·ï¼ˆå¦‚ aws_docs_searchï¼‰è·å–å‡†ç¡®çš„ AWS æœåŠ¡ä¿¡æ¯
4. å¦‚æœéœ€è¦æœ¬åœ°çŸ¥è¯†åº“ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨ search_context å·¥å…·æ£€ç´¢ç›¸å…³ä¿¡æ¯

ç„¶ååŸºäºæ£€ç´¢ç»“æœæä¾›ä¸“ä¸šçš„å›ç­”ã€‚

å›ç­”æ ¼å¼å»ºè®®ï¼š
## é—®é¢˜åˆ†æ
## ä¸»è¦å»ºè®®
## å®æ–½æ­¥éª¤
## æ³¨æ„äº‹é¡¹
## ç›¸å…³æ–‡æ¡£
"""
    
    def _extract_content_from_chunk(self, chunk) -> str:
        """ä»æµå¼å“åº”å—ä¸­æå–å†…å®¹"""
        if hasattr(chunk, 'content'):
            return chunk.content
        elif hasattr(chunk, 'text'):
            return chunk.text
        elif isinstance(chunk, str):
            return chunk
        elif hasattr(chunk, 'delta') and hasattr(chunk.delta, 'content'):
            return chunk.delta.content
        elif hasattr(chunk, 'choices') and len(chunk.choices) > 0:
            # OpenAI æ ¼å¼
            choice = chunk.choices[0]
            if hasattr(choice, 'delta') and hasattr(choice.delta, 'content'):
                return choice.delta.content or ""
        else:
            # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            try:
                return str(chunk)
            except:
                return ""
    
    def _format_streaming_content(self, content: str) -> str:
        """æ ¼å¼åŒ–æµå¼å†…å®¹ï¼Œæ·»åŠ é€‚å½“çš„æ¢è¡Œ"""
        import re
        
        # å®šä¹‰éœ€è¦æ¢è¡Œçš„å…³é”®è¯å’Œæ¨¡å¼
        thinking_patterns = [
            r'è®©æˆ‘ä¸ºæ‚¨æ£€ç´¢',
            r'åŸºäºè·å–çš„ä¿¡æ¯',
            r'æˆ‘éœ€è¦è¿›ä¸€æ­¥äº†è§£',
            r'éœ€è¦æ›´å¤šå…³äº',
            r'è®©æˆ‘å†æŸ¥è¯¢',
            r'æ ¹æ®æ£€ç´¢ç»“æœ',
            r'## é—®é¢˜åˆ†æ',
            r'## ä¸»è¦å»ºè®®',
            r'## å®æ–½æ­¥éª¤',
            r'## æ³¨æ„äº‹é¡¹',
            r'## ç›¸å…³æ–‡æ¡£'
        ]
        
        # ä¸ºæ€è€ƒè¿‡ç¨‹æ·»åŠ æ¢è¡Œ
        formatted_content = content
        for pattern in thinking_patterns:
            # åœ¨åŒ¹é…çš„æ¨¡å¼å‰æ·»åŠ æ¢è¡Œï¼ˆå¦‚æœå‰é¢ä¸æ˜¯æ¢è¡Œçš„è¯ï¼‰
            formatted_content = re.sub(
                f'([^\\n])({pattern})', 
                r'\1\n\n\2', 
                formatted_content
            )
        
        # åœ¨å†’å·åæ·»åŠ æ¢è¡Œï¼ˆç”¨äº"å†…å®¹ï¼š"è¿™æ ·çš„æ¨¡å¼ï¼‰
        formatted_content = re.sub(r'ï¼š([^\\n])', r'ï¼š\n\1', formatted_content)
        
        return formatted_content
    
    def _stream_text_output(self, text):
        """å°†æ–‡æœ¬æŒ‰è¯è¯­æµå¼è¾“å‡º - ä¼˜åŒ–ç‰ˆæœ¬"""
        import re
        import time
        
        logger.debug(f"ğŸ“ å¼€å§‹æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œå†…å®¹é•¿åº¦: {len(text)}")
        
        # æŒ‰è¯è¯­å’Œæ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼Œä½†æ˜¯ä»¥æ›´å¤§çš„å—ä¸ºå•ä½
        # è¿™æ ·å¯ä»¥çœ‹åˆ°æµå¼æ•ˆæœï¼Œä½†ä¸ä¼šå¤ªæ…¢
        chunks = []
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+|\d+|[^\w\s]|\s+', text)
        
        # å°†å•è¯ç»„åˆæˆæ›´å¤§çš„å—ï¼ˆæ¯3-5ä¸ªè¯ä¸ºä¸€å—ï¼‰
        current_chunk = ""
        for i, word in enumerate(words):
            current_chunk += word
            
            # æ¯3-5ä¸ªè¯æˆ–é‡åˆ°å¥å·ã€æ¢è¡Œç¬¦æ—¶åˆ›å»ºä¸€ä¸ªå—
            if (i + 1) % 4 == 0 or word in ['.', 'ã€‚', '\n', '!', 'ï¼', '?', 'ï¼Ÿ']:
                if current_chunk.strip():
                    chunks.append(current_chunk)
                    current_chunk = ""
        
        # æ·»åŠ å‰©ä½™çš„å†…å®¹
        if current_chunk.strip():
            chunks.append(current_chunk)
        
        accumulated = ""
        
        for chunk in chunks:
            accumulated += chunk
            
            yield {
                "type": "content",
                "content": chunk,
                "accumulated": accumulated,
                "timestamp": datetime.now().isoformat()
            }
            
            # æ·»åŠ é€‚å½“çš„å»¶è¿Ÿæ¥æ¨¡æ‹Ÿæµå¼æ•ˆæœ
            time.sleep(0.1)  # 100ms å»¶è¿Ÿï¼Œè¶³å¤Ÿçœ‹åˆ°æµå¼æ•ˆæœä½†ä¸ä¼šå¤ªæ…¢
    


    
    def process_query_stream_simple(self, user_query: str, user_id: str = None):
        """
        ç®€åŒ–ç‰ˆæµå¼å¤„ç† - ç”¨äºè°ƒè¯•
        """
        try:
            logger.debug(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] å¼€å§‹å¤„ç†æŸ¥è¯¢: {user_query}")
            logger.debug(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] MCP Client çŠ¶æ€: {self.mcp_client is not None}")
            
            # ç›´æ¥è¿”å›ä¸€ä¸ªæµ‹è¯•å“åº”
            test_response = f"æ”¶åˆ°æ‚¨çš„é—®é¢˜ï¼š{user_query}\n\nè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å“åº”ï¼Œç”¨äºéªŒè¯æµå¼è¾“å‡ºæ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"
            
            logger.debug(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] å¼€å§‹æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œå†…å®¹é•¿åº¦: {len(test_response)}")
            
            # æ¨¡æ‹Ÿæµå¼è¾“å‡º
            chunk_count = 0
            for chunk in self._stream_text_output(test_response):
                chunk_count += 1
                print(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] ç”Ÿæˆç¬¬ {chunk_count} ä¸ªæ•°æ®å—: {chunk}")
                yield chunk
            
            logger.debug(f"âœ… [ç®€åŒ–ç‰ˆ] æµå¼è¾“å‡ºå®Œæˆï¼Œå…±ç”Ÿæˆ {chunk_count} ä¸ªæ•°æ®å—")
                
        except Exception as e:
            print(f"âŒ [ç®€åŒ–ç‰ˆ] å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            print(f"âŒ [ç®€åŒ–ç‰ˆ] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            yield {
                "type": "error",
                "error": f"ç®€åŒ–ç‰ˆå¤„ç†å¤±è´¥: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

    async def _handle_otel_context_error(self, coro):
        """
        å¤„ç† OpenTelemetry ä¸Šä¸‹æ–‡é”™è¯¯çš„è¾…åŠ©å‡½æ•°
        
        Args:
            coro: è¦æ‰§è¡Œçš„åç¨‹
            
        Returns:
            åç¨‹çš„ç»“æœ
        """
        try:
            return await coro
        except ValueError as e:
            if "was created in a different Context" in str(e):
                # å¿½ç•¥ OpenTelemetry ä¸Šä¸‹æ–‡é”™è¯¯
                logger.debug(f"å¿½ç•¥ OpenTelemetry ä¸Šä¸‹æ–‡é”™è¯¯: {str(e)}")
                return None
            else:
                # é‡æ–°æŠ›å‡ºå…¶ä»– ValueError
                raise

    async def process_query_stream(self, user_query: str, user_id: str = None):
        """
        æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - ä½¿ç”¨ Strands Agent çœŸæ­£çš„æµå¼å“åº”
        ä¿è¯ LLM å†…å®¹å’Œ MCP Server å·¥å…·å†…å®¹éƒ½èƒ½æµå¼è¿”å›åˆ°é¡µé¢ï¼Œå¹¶åœ¨åå°æ‰“å°ã€‚
        """
        if not self.mcp_client:
            yield {
                "type": "error",
                "error": "MCP å®¢æˆ·ç«¯æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥å®‰è£…å’Œé…ç½®",
                "timestamp": datetime.now().isoformat()
            }
            return

        try:
            logger.debug(f"ğŸ“ å¼€å§‹æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢: {user_query}")
            
            # è·å–ä¸»MCPæœåŠ¡å™¨çš„å·¥å…·
            with self.mcp_client:
                mcp_tools = self.mcp_client.list_tools_sync()
                logger.debug(f"ğŸ”§ è·å–åˆ° {len(mcp_tools)} ä¸ªä¸»MCPå·¥å…·")
            
            # è·å–langgraph-crawler MCPæœåŠ¡å™¨çš„å·¥å…·
            crawler_tools = []
            try:
                with self.langgraph_crawler_client:
                    crawler_tools = self.langgraph_crawler_client.list_tools_sync()
                    logger.debug(f"ğŸ”§ è·å–åˆ° {len(crawler_tools)} ä¸ªlanggraph-crawlerå·¥å…·")
            except Exception as crawler_error:
                logger.error(f"âš ï¸ è·å–langgraph-crawlerå·¥å…·å¤±è´¥: {str(crawler_error)}")
            
            # è·å–AWSæ–‡æ¡£MCPæœåŠ¡å™¨çš„å·¥å…·
            aws_docs_tools = []
            try:
                with self.aws_docs_client:
                    aws_docs_tools = self.aws_docs_client.list_tools_sync()
                    logger.debug(f"ğŸ”§ è·å–åˆ° {len(aws_docs_tools)} ä¸ªAWSæ–‡æ¡£å·¥å…·")
            except Exception as aws_docs_error:
                logger.error(f"âš ï¸ è·å–AWSæ–‡æ¡£å·¥å…·å¤±è´¥: {str(aws_docs_error)}")
            
            # åˆå¹¶æ‰€æœ‰å·¥å…·
            all_tools = mcp_tools + mem0_tools + crawler_tools + aws_docs_tools
            logger.debug(f"ğŸ”§ æ€»å…±è·å–åˆ° {len(all_tools)} ä¸ªå·¥å…·: {len(mcp_tools)}ä¸ªä¸»MCPå·¥å…· + {len(mem0_tools)}ä¸ªmem0å·¥å…· + {len(crawler_tools)}ä¸ªcrawlerå·¥å…· + {len(aws_docs_tools)}ä¸ªAWSæ–‡æ¡£å·¥å…·")
            
            # ä½¿ç”¨ä¸»MCPå®¢æˆ·ç«¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            with self.mcp_client:
                try:
                    logger.debug("ğŸ”§ å¼€å§‹åˆ›å»º BedrockModel...")
                    try:
                        bedrock_model = BedrockModel(
                            model_id=self.bedorck_model,
                            region_name=self.bedrock_region,
                            temperature=0.3,
                        )
                        logger.debug("âœ… BedrockModel åˆ›å»ºæˆåŠŸ")
                    except Exception as bedrock_error:
                        import traceback
                        logger.error(f"âŒ BedrockModel åˆ›å»ºå¤±è´¥: {str(bedrock_error)}")
                        logger.error(f"BedrockModel é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
                        raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸
                    
                    # æ ¹æ®ä¼šè¯ç®¡ç†å¯ç”¨æ€§å†³å®šå¦‚ä½•åˆ›å»º Agent
                    if SESSION_MANAGEMENT_AVAILABLE:
                        # åˆ›å»º Strands ä¼šè¯ç®¡ç†å™¨ - ç”¨äºçŸ­æœŸè®°å¿†
                        logger.debug(f"ğŸ”„ ä¸ºç”¨æˆ· {user_id} åˆ›å»ºä¼šè¯ç®¡ç†å™¨")
                        try:
                            session_manager = FileSessionManager(
                                session_id=user_id,
                                storage_dir=self.sessions_dir
                            )
                            logger.debug(f"âœ… ä¼šè¯ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ: session_id={user_id}")
                        except Exception as session_error:
                            import traceback
                            logger.error(f"âŒ ä¼šè¯ç®¡ç†å™¨åˆ›å»ºå¤±è´¥: {str(session_error)}")
                            logger.error(f"ä¼šè¯ç®¡ç†å™¨é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
                            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸
                        
                        # åˆ›å»º Agent æ—¶ä½¿ç”¨ä¼šè¯ç®¡ç†å™¨
                        logger.debug("ğŸ”§ å¼€å§‹åˆ›å»ºå¸¦ä¼šè¯ç®¡ç†çš„ Agent...")
                        try:
                            agent = Agent(
                                tools=all_tools,
                                callback_handler=None,
                                session_manager=session_manager,  # æ·»åŠ ä¼šè¯ç®¡ç†å™¨
                                model=bedrock_model
                            )
                            logger.debug("âœ… æˆåŠŸåˆ›å»ºä½¿ç”¨ Agent å¹¶é…ç½®ä¼šè¯ç®¡ç†")
                        except Exception as agent_error:
                            import traceback
                            logger.error(f"âŒ åˆ›å»ºå¸¦ä¼šè¯ç®¡ç†çš„ Agent å¤±è´¥: {str(agent_error)}")
                            logger.error(f"Agent åˆ›å»ºé”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
                            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸
                    else:
                        # ä¸ä½¿ç”¨ä¼šè¯ç®¡ç†å™¨åˆ›å»º Agent
                        logger.debug("ğŸ”§ å¼€å§‹åˆ›å»ºä¸å¸¦ä¼šè¯ç®¡ç†çš„ Agent...")
                        try:
                            agent = Agent(
                                tools=all_tools,
                                callback_handler=None,
                                model=bedrock_model
                            )
                            logger.debug("âœ… æˆåŠŸåˆ›å»ºä½¿ç”¨ Agent (æ— ä¼šè¯ç®¡ç†)")
                        except Exception as agent_error:
                            import traceback
                            logger.error(f"âŒ åˆ›å»ºä¸å¸¦ä¼šè¯ç®¡ç†çš„ Agent å¤±è´¥: {str(agent_error)}")
                            logger.error(f"Agent åˆ›å»ºé”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
                            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸
                except Exception as model_error:
                    import traceback
                    logger.error(f"âš ï¸ ä½¿ç”¨ Claude 4.0 Sonnet åˆ›å»º Agent å¤±è´¥: {str(model_error)}")
                    logger.error(f"è¯¦ç»†é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
                    logger.error("å°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹åˆ›å»º Agent")
                    
                    # æ ¹æ®ä¼šè¯ç®¡ç†å¯ç”¨æ€§å†³å®šå¦‚ä½•åˆ›å»º Agent
                    try:
                        if SESSION_MANAGEMENT_AVAILABLE:
                            # åˆ›å»ºä¼šè¯ç®¡ç†å™¨ä½†ä½¿ç”¨é»˜è®¤æ¨¡å‹
                            logger.debug(f"ğŸ”„ ä¸ºç”¨æˆ· {user_id} åˆ›å»ºå¤‡ç”¨ä¼šè¯ç®¡ç†å™¨")
                            try:
                                session_manager = FileSessionManager(
                                    session_id=user_id,
                                    storage_dir=self.sessions_dir
                                )
                                logger.debug(f"âœ… å¤‡ç”¨ä¼šè¯ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ")
                            except Exception as session_error:
                                import traceback
                                logger.error(f"âŒ å¤‡ç”¨ä¼šè¯ç®¡ç†å™¨åˆ›å»ºå¤±è´¥: {str(session_error)}")
                                logger.error(f"å¤‡ç”¨ä¼šè¯ç®¡ç†å™¨é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
                                raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸
                            
                            logger.debug("ğŸ”§ å¼€å§‹åˆ›å»ºå¸¦ä¼šè¯ç®¡ç†çš„å¤‡ç”¨ Agent...")
                            agent = Agent(
                                tools=all_tools, 
                                callback_handler=None,
                                session_manager=session_manager  # æ·»åŠ ä¼šè¯ç®¡ç†å™¨
                            )
                            logger.debug("âœ… æˆåŠŸåˆ›å»ºå¸¦ä¼šè¯ç®¡ç†çš„å¤‡ç”¨ Agent")
                        else:
                            # ä¸ä½¿ç”¨ä¼šè¯ç®¡ç†å™¨åˆ›å»º Agent
                            logger.debug("ğŸ”§ å¼€å§‹åˆ›å»ºä¸å¸¦ä¼šè¯ç®¡ç†çš„å¤‡ç”¨ Agent...")
                            agent = Agent(
                                tools=all_tools, 
                                callback_handler=None
                            )
                            logger.debug("âœ… æˆåŠŸåˆ›å»ºä¸å¸¦ä¼šè¯ç®¡ç†çš„å¤‡ç”¨ Agent")
                    except Exception as fallback_error:
                        import traceback
                        logger.error(f"âŒ åˆ›å»ºå¤‡ç”¨ Agent å¤±è´¥: {str(fallback_error)}")
                        logger.error(f"å¤‡ç”¨ Agent é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
                        # æœ€åçš„å°è¯• - åˆ›å»ºä¸€ä¸ªæ²¡æœ‰ä»»ä½•é¢å¤–é…ç½®çš„åŸºæœ¬ Agent
                        logger.error("ğŸ”„ æœ€åå°è¯•åˆ›å»ºåŸºæœ¬ Agent...")
                        agent = Agent()
                if hasattr(agent, 'model') and hasattr(agent.model, 'config'):
                    logger.debug(f"ğŸ”§ ä½¿ç”¨æ¨¡å‹é…ç½®: {agent.model.config}")
                else:
                    logger.warn("âš ï¸ æ— æ³•è·å–æ¨¡å‹é…ç½®ä¿¡æ¯")
                user_mem0 = create_mem0_integration(user_id)
                from mem0_tools import set_current_user_mem0
                set_current_user_mem0(user_mem0)
                historical_context = user_mem0.get_context_for_query(user_query)
                system_instructions = self._get_instructions()
                if historical_context:
                    full_query = f"{system_instructions}\n\n{historical_context}\n\nç”¨æˆ·é—®é¢˜: {user_query}"
                    logger.debug(f"ğŸ“š æ·»åŠ äº†å†å²ä¸Šä¸‹æ–‡ï¼Œé•¿åº¦: {len(historical_context)}")
                else:
                    full_query = f"{system_instructions}\n\nç”¨æˆ·é—®é¢˜: {user_query}"
                logger.debug(f"ğŸ”§ å¼€å§‹ Strands Agent æµå¼è°ƒç”¨...")
                accumulated_response = ""
                async def async_stream():
                    nonlocal accumulated_response
                    try:
                        # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
                        timeout_seconds = 240  # å¢åŠ åˆ°240ç§’
                        
                        # è·å–æµå¼å“åº”è¿­ä»£å™¨
                        try:
                            stream_iterator = agent.stream_async(full_query)
                            logger.debug("âœ… æˆåŠŸè·å–æµå¼å“åº”è¿­ä»£å™¨")
                        except Exception as stream_error:
                            logger.error(f"âŒ è·å–æµå¼å“åº”è¿­ä»£å™¨å¤±è´¥: {str(stream_error)}")
                            import traceback
                            logger.error(f"æµå¼å“åº”è¿­ä»£å™¨é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
                            raise
                        
                        # åˆå§‹åŒ–å¿ƒè·³è®¡æ•°å™¨
                        heartbeat_counter = 0
                        last_heartbeat_time = datetime.now()
                        
                        # å¤„ç†æµå¼å“åº”
                        while True:
                            # æ¯5ç§’å‘é€ä¸€æ¬¡å¿ƒè·³ï¼Œä¿æŒè¿æ¥æ´»è·ƒ
                            current_time = datetime.now()
                            if (current_time - last_heartbeat_time).total_seconds() >= 5:
                                yield {
                                    "type": "heartbeat",
                                    "timestamp": current_time.isoformat()
                                }
                                last_heartbeat_time = current_time
                                heartbeat_counter += 1
                            
                            # ç­‰å¾…æµå¼å“åº”æˆ–è¶…æ—¶
                            try:
                                # ä½¿ç”¨asyncio.wait_forè®¾ç½®è¶…æ—¶ï¼Œä½†å¢åŠ è¶…æ—¶æ—¶é—´
                                try:
                                    event = await asyncio.wait_for(stream_iterator.__anext__(), timeout=10.0)
                                except ValueError as ve:
                                    if "was created in a different Context" in str(ve):
                                        # å¿½ç•¥ OpenTelemetry ä¸Šä¸‹æ–‡é”™è¯¯å¹¶ç»§ç»­
                                        logger.debug(f"å¿½ç•¥ OpenTelemetry ä¸Šä¸‹æ–‡é”™è¯¯: {str(ve)}")
                                        continue
                                    else:
                                        # é‡æ–°æŠ›å‡ºå…¶ä»– ValueError
                                        raise
                                
                                # å¤„ç†äº‹ä»¶
                                # LLM å†…å®¹æµå¼è¿”å›
                                if "data" in event:
                                    content = event["data"]
                                    if content:
                                        accumulated_response += content
                                        logger.debug(f"ğŸ“ LLMæµå¼å†…å®¹: {content}")
                                        yield {
                                            "type": "content",
                                            "content": content,
                                            "accumulated": accumulated_response,
                                            "timestamp": datetime.now().isoformat()
                                        }
                                
                                # å·¥å…·è°ƒç”¨äº‹ä»¶
                                if "current_tool_use" in event and event["current_tool_use"].get("name"):
                                    tool_name = event["current_tool_use"]["name"]
                                    tool_input = event["current_tool_use"].get("input", {})
                                    logger.debug(f"ğŸ”§ å·¥å…·è°ƒç”¨: {tool_name}, è¾“å…¥: {tool_input}")
                                    
                                    # å¯¹ç½‘ç»œæœç´¢å·¥å…·æ·»åŠ ç‰¹æ®Šå¤„ç†
                                    if "web_search" in tool_name.lower() or "crawl" in tool_name.lower():
                                        yield {
                                            "type": "status",
                                            "message": f"[æ­£åœ¨æœç´¢ç½‘ç»œä¿¡æ¯: {tool_input.get('query', '')}]",
                                            "timestamp": datetime.now().isoformat()
                                        }
                                    else:
                                        yield {
                                            "type": "status",
                                            "message": f"[ä½¿ç”¨å·¥å…·: {tool_name}]",
                                            "timestamp": datetime.now().isoformat()
                                        }
                                
                                # MCP Server å·¥å…·è¿”å›å†…å®¹
                                if "tool_response" in event and event["tool_response"]:
                                    tool_name = event.get("current_tool_use", {}).get("name", "æœªçŸ¥å·¥å…·")
                                    logger.debug(f"ğŸŸ¢ å·¥å…· {tool_name} è¿”å›ç»“æœ")
                                    
                                    # å¯¹äºç½‘ç»œæœç´¢å·¥å…·ï¼Œé€šçŸ¥å‰ç«¯æœç´¢å®Œæˆ
                                    if "web_search" in tool_name.lower() or "crawl" in tool_name.lower():
                                        yield {
                                            "type": "status",
                                            "message": f"[ç½‘ç»œæœç´¢å®Œæˆï¼Œæ­£åœ¨åˆ†æç»“æœ]",
                                            "timestamp": datetime.now().isoformat()
                                        }
                                
                            except StopAsyncIteration:
                                # æµç»“æŸ
                                logger.debug("âœ… æµå¼å“åº”å®Œæˆ")
                                break
                                
                            except asyncio.TimeoutError:
                                # è¶…æ—¶ä½†ä¸ä¸­æ–­æµç¨‹ï¼Œç»§ç»­ç­‰å¾…
                                logger.debug(f"â±ï¸ ç­‰å¾…æµå¼å“åº”ä¸­... ({heartbeat_counter * 10}ç§’)")
                                
                                # å¦‚æœè¶…è¿‡æ€»è¶…æ—¶æ—¶é—´ï¼Œå‘é€çŠ¶æ€æ¶ˆæ¯ä½†ä¸ä¸­æ–­
                                if heartbeat_counter * 10 > timeout_seconds:
                                    logger.warning(f"âš ï¸ æµå¼å“åº”å¤„ç†æ—¶é—´è¾ƒé•¿ ({timeout_seconds}ç§’)")
                                    yield {
                                        "type": "status",
                                        "message": f"[å¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œå¯èƒ½æ˜¯ç½‘ç»œæœç´¢æˆ–åˆ†æå¤æ‚é—®é¢˜å¯¼è‡´ï¼Œè¯·è€å¿ƒç­‰å¾…...]",
                                        "timestamp": datetime.now().isoformat()
                                    }
                            
                            except Exception as event_error:
                                # å¤„ç†å•ä¸ªäº‹ä»¶çš„é”™è¯¯ï¼Œä½†ä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                                logger.error(f"âŒ å¤„ç†äº‹ä»¶æ—¶å‡ºé”™: {str(event_error)}")
                                yield {
                                    "type": "status",
                                    "message": f"[å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œä½†ä»åœ¨ç»§ç»­...]",
                                    "timestamp": datetime.now().isoformat()
                                }
                    except Exception as e:
                        logger.error(f"âŒ å¼‚æ­¥æµå¼è°ƒç”¨å¤±è´¥: {str(e)}")
                        import traceback
                        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                        yield {
                            "type": "error",
                            "error": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
                            "timestamp": datetime.now().isoformat()
                        }
                async for chunk in async_stream():
                    yield chunk
                if accumulated_response:
                    try:
                        # ä¿å­˜åˆ°é•¿æœŸè®°å¿† (mem0)
                        user_mem0.add_memory(
                            message="EMRå‡çº§å’¨è¯¢å¯¹è¯",
                            user_query=user_query,
                            response=accumulated_response,
                            metadata={
                                "user_id": user_id,
                                "response_length": len(accumulated_response)
                            }
                        )
                        logger.debug(f"ğŸ’¾ å¯¹è¯é•¿æœŸè®°å¿†å·²ä¿å­˜åˆ° mem0 {user_id}")
                        
                        # çŸ­æœŸè®°å¿†å¤„ç†
                        if SESSION_MANAGEMENT_AVAILABLE:
                            # çŸ­æœŸè®°å¿†ç”± Strands ä¼šè¯ç®¡ç†å™¨è‡ªåŠ¨å¤„ç†
                            logger.debug(f"ğŸ’¾ å¯¹è¯çŸ­æœŸè®°å¿†å·²ç”± Strands ä¼šè¯ç®¡ç†å™¨è‡ªåŠ¨ä¿å­˜ (session_id: {user_id})")
                        else:
                            logger.debug(f"âš ï¸ Strands ä¼šè¯ç®¡ç†ä¸å¯ç”¨ï¼ŒçŸ­æœŸè®°å¿†æœªä¿å­˜")
                    except Exception as mem_error:
                        logger.error(f"âš ï¸ ä¿å­˜è®°å¿†å¤±è´¥: {str(mem_error)}")
        except Exception as e:
            logger.error(f"âŒ æµå¼å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")
            yield {
                "type": "error",
                "error": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

    async def process_query(self, user_query: str, user_id: str = None) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢å†…å®¹
            user_id: ç”¨æˆ·ID
            
        Returns:
            åŒ…å«å›ç­”å’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
        """
        if not self.mcp_client:
            return {
                "success": False,
                "error": "MCP å®¢æˆ·ç«¯æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥å®‰è£…å’Œé…ç½®",
                "timestamp": datetime.now().isoformat()
            }
        
        try:
            logger.info(f"ğŸ“ å¤„ç†ç”¨æˆ·æŸ¥è¯¢: {user_query}")
            
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå¿…é¡»åœ¨ MCP å®¢æˆ·ç«¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­ä½¿ç”¨ Agent
            with self.mcp_client:
                # è·å– MCP æœåŠ¡å™¨æä¾›çš„å·¥å…·
                tools = self.mcp_client.list_tools_sync()
                logger.debug(f"ğŸ”§ è·å–åˆ° {len(tools)} ä¸ª MCP å·¥å…·")
                
                # åœ¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­åˆ›å»º Agent
                # æ ¹æ® Strands Agents APIï¼ŒAgent åˆå§‹åŒ–ä¸æ¥å— instructions å‚æ•°
                agent = Agent(tools=tools)
                
                # æ„å»ºåŒ…å«ç³»ç»ŸæŒ‡ä»¤çš„å®Œæ•´æŸ¥è¯¢
                system_instructions = self._get_instructions()
                full_query = f"{system_instructions}\n\nç”¨æˆ·é—®é¢˜: {user_query}"
                
                # ä½¿ç”¨ Agent å¤„ç†æŸ¥è¯¢
                response = agent(full_query)
                
                logger.debug("âœ… Strands Agent å¤„ç†å®Œæˆ")
                
                # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå“åº”æ ¼å¼å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡
                if isinstance(response, str):
                    answer = response
                    tools_used = []
                else:
                    answer = getattr(response, 'content', str(response))
                    tools_used = getattr(response, 'tools_used', [])
                
                return {
                    "success": True,
                    "answer": answer,
                    "tools_used": tools_used,
                    "query": user_query,
                    "timestamp": datetime.now().isoformat()
                }
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")
            return {
                "success": False,
                "error": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

# åˆå§‹åŒ–åŠ©æ‰‹
emr_assistant = EMRUpgradeAssistant()

@app.route('/')
async def index():
    """ä¸»é¡µ - ç”Ÿæˆå¹¶å­˜å‚¨ç”¨æˆ·ID"""
    # æ£€æŸ¥ä¼šè¯ä¸­æ˜¯å¦å·²æœ‰ç”¨æˆ·IDï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
    if 'user_id' not in session:
        session['user_id'] = str(uuid.uuid4())
        logger.info(f"åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {session['user_id']}")
    else:
        logger.info(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {session['user_id']}")
    
    return await render_template('index.html')

@app.route('/chat', methods=['POST'])
async def chat_stream():
    """å¤„ç†èŠå¤©è¯·æ±‚ - æµå¼å“åº”"""
    try:
        data = await request.get_json()
        user_query = data.get('query', '').strip()
        
        if not user_query:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥æ‚¨çš„é—®é¢˜'
            }), 400
        
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨èŠå¤©è¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # è¿”å›æµå¼å“åº” - å¼ºåˆ¶å®æ—¶ä¼ è¾“ï¼Œæ·»åŠ å¡«å……æ•°æ®
        async def generate_stream():
            import sys
            import os
            
            # å¼ºåˆ¶ç¦ç”¨ Python çš„è¾“å‡ºç¼“å†²
            os.environ['PYTHONUNBUFFERED'] = '1'
            
            try:
                logger.debug("ğŸ”„ å¼€å§‹ç”Ÿæˆæµå¼å“åº”...")
                
                # ç«‹å³å‘é€å¿ƒè·³å’Œå¡«å……æ•°æ®ï¼Œå¼ºåˆ¶å»ºç«‹è¿æ¥
                heartbeat = json.dumps({'type': 'heartbeat'})
                yield f"data: {heartbeat}\n\n"
                
                # å‘é€å¡«å……æ•°æ®ï¼Œå¼ºåˆ¶ Flask ç«‹å³å‘é€å“åº”å¤´
                padding = " " * 1024  # 1KB å¡«å……æ•°æ®
                yield f": padding {padding}\n\n"
                
                logger.debug("ğŸ“¡ å¿ƒè·³å’Œå¡«å……æ•°æ®å·²å‘é€ï¼Œå¼€å§‹å¤„ç†æŸ¥è¯¢...")
                
                # å…ˆå‘é€ä¸€ä¸ªåˆå§‹å†…å®¹ï¼Œç¡®ä¿å‰ç«¯èƒ½ç«‹å³æ˜¾ç¤º
                initial_content = {
                    "type": "content",
                    "content": "æ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜...\n\n",
                    "accumulated": "æ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜...\n\n",
                    "timestamp": datetime.now().isoformat()
                }
                yield f"data: {json.dumps(initial_content, ensure_ascii=False)}\n\n"
                yield f": initial-content\n\n"
                
                # ä½¿ç”¨å®Œæ•´çš„ Strands Agent æµå¼å¤„ç†
                chunk_count = 0
                async for chunk in emr_assistant.process_query_stream(user_query, user_id):
                    chunk_count += 1
                    logger.debug(f"ç”Ÿæˆç¬¬ {chunk_count} ä¸ªæ•°æ®å—: {chunk}")
                    
                    # ç¡®ä¿ JSON åºåˆ—åŒ–ä¸ä¼šå¤±è´¥
                    try:
                        chunk_data = json.dumps(chunk, ensure_ascii=False)
                    except Exception as json_err:
                        print(f"JSON åºåˆ—åŒ–å¤±è´¥: {str(json_err)}, å°è¯•ç®€åŒ–æ•°æ®")
                        # å¦‚æœåºåˆ—åŒ–å¤±è´¥ï¼Œå°è¯•ç®€åŒ–æ•°æ®
                        simplified_chunk = {
                            "type": chunk.get("type", "content"),
                            "content": str(chunk.get("content", "")),
                            "timestamp": datetime.now().isoformat()
                        }
                        chunk_data = json.dumps(simplified_chunk, ensure_ascii=False)
                    
                    # ç«‹å³å‘é€æ•°æ®ï¼Œç¡®ä¿æ¯ä¸ªå—éƒ½æœ‰å®Œæ•´çš„ SSE æ ¼å¼
                    yield f"data: {chunk_data}\n\n"
                    
                    # æ·»åŠ å°çš„å¡«å……æ•°æ®ç¡®ä¿ç«‹å³ä¼ è¾“
                    yield f": chunk-{chunk_count}\n\n"
                    
                    # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
                    sys.stdout.flush()
                    sys.stderr.flush()
                
                # å‘é€ç»“æŸä¿¡å·
                end_data = json.dumps({'type': 'end'})
                yield f"data: {end_data}\n\n"
                
                print(f"âœ… æµå¼å“åº”å®Œæˆï¼Œå…±å‘é€ {chunk_count} ä¸ªæ•°æ®å—")
                
            except Exception as e:
                import traceback
                logger.error(f"âŒ æµå¼å“åº”é”™è¯¯: {str(e)}")
                print(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                error_data = json.dumps({'type': 'error', 'error': str(e)})
                yield f"data: {error_data}\n\n"
        
        return Response(
            generate_stream(), 
            content_type='text/event-stream',
            headers={
                'Cache-Control': 'no-cache, no-store, must-revalidate',
                'Connection': 'keep-alive',
                'X-Accel-Buffering': 'no',  # ç¦ç”¨Nginxç¼“å†²
                'Transfer-Encoding': 'chunked'  # ä½¿ç”¨åˆ†å—ä¼ è¾“ç¼–ç 
            }
        )
        
    except Exception as e:
        import traceback
        logger.error(f"âŒ å¤„ç†èŠå¤©è¯·æ±‚å¤±è´¥: {str(e)}")
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        return jsonify({
            'success': False,
            'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/chat-sync', methods=['POST'])
async def chat_sync():
    """å¤„ç†èŠå¤©è¯·æ±‚ - åŒæ­¥å“åº”ï¼ˆå¤‡ç”¨ï¼‰"""
    try:
        data = await request.get_json()
        user_query = data.get('query', '').strip()
        
        if not user_query:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥æ‚¨çš„é—®é¢˜'
            }), 400
        
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨chat-syncè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # å¤„ç†æŸ¥è¯¢
        result = await emr_assistant.process_query(user_query, user_id)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/memory/stats')
async def memory_stats():
    """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
    try:
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨memory/statsè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        stats = user_mem0.get_memory_stats()
        
        return jsonify({
            'success': True,
            'stats': stats,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–è®°å¿†ç»Ÿè®¡å¤±è´¥: {str(e)}'
        }), 500

@app.route('/session/clear', methods=['POST'])
async def clear_session():
    """æ¸…é™¤å½“å‰ä¼šè¯"""
    try:
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·ID
        user_id = session.get('user_id')
        if not user_id:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ´»åŠ¨çš„ä¼šè¯'
            }), 400
        
        # æ£€æŸ¥ä¼šè¯ç®¡ç†æ˜¯å¦å¯ç”¨
        if not SESSION_MANAGEMENT_AVAILABLE:
            # å³ä½¿ä¼šè¯ç®¡ç†ä¸å¯ç”¨ï¼Œä¹Ÿç”Ÿæˆæ–°çš„ä¼šè¯ID
            new_user_id = str(uuid.uuid4())
            session['user_id'] = new_user_id
            logger.info(f"âœ… å·²ä¸ºç”¨æˆ·åˆ›å»ºæ–°çš„ä¼šè¯ID: {new_user_id}")
            
            return jsonify({
                'success': True,
                'message': 'ä¼šè¯ç®¡ç†ä¸å¯ç”¨ï¼Œä½†å·²åˆ›å»ºæ–°ä¼šè¯ID',
                'new_session_id': new_user_id,
                'timestamp': datetime.now().isoformat()
            })
        
        # åˆ é™¤ä¼šè¯ç›®å½•
        import shutil
        sessions_dir = os.path.join(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')), 'sessions')
        session_dir = os.path.join(sessions_dir, f"session_{user_id}")
        
        if os.path.exists(session_dir):
            shutil.rmtree(session_dir)
            logger.info(f"âœ… å·²æ¸…é™¤ç”¨æˆ· {user_id} çš„ä¼šè¯æ•°æ®")
            
            # ç”Ÿæˆæ–°çš„ä¼šè¯ID
            new_user_id = str(uuid.uuid4())
            session['user_id'] = new_user_id
            logger.info(f"âœ… å·²ä¸ºç”¨æˆ·åˆ›å»ºæ–°çš„ä¼šè¯ID: {new_user_id}")
            
            return jsonify({
                'success': True,
                'message': 'ä¼šè¯å·²æ¸…é™¤ï¼Œå·²åˆ›å»ºæ–°ä¼šè¯',
                'new_session_id': new_user_id,
                'timestamp': datetime.now().isoformat()
            })
        else:
            # å³ä½¿ä¼šè¯ç›®å½•ä¸å­˜åœ¨ï¼Œä¹Ÿç”Ÿæˆæ–°çš„ä¼šè¯ID
            new_user_id = str(uuid.uuid4())
            session['user_id'] = new_user_id
            logger.info(f"âœ… å·²ä¸ºç”¨æˆ·åˆ›å»ºæ–°çš„ä¼šè¯ID: {new_user_id}")
            
            return jsonify({
                'success': True,
                'message': 'ä¼šè¯æ•°æ®ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºæ–°ä¼šè¯ID',
                'new_session_id': new_user_id,
                'timestamp': datetime.now().isoformat()
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æ¸…é™¤ä¼šè¯å¤±è´¥: {str(e)}'
        }), 500

@app.route('/memory/search', methods=['POST'])
async def search_memories():
    """æœç´¢å†å²è®°å¿†"""
    try:
        data = await request.get_json()
        query = data.get('query', '').strip()
        limit = data.get('limit', 5)
        
        if not query:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥æœç´¢æŸ¥è¯¢'
            }), 400
        
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨memory/searchè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        memories = user_mem0.search_memories(query, limit)
        
        return jsonify({
            'success': True,
            'memories': memories,
            'query': query,
            'count': len(memories),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æœç´¢è®°å¿†å¤±è´¥: {str(e)}'
        }), 500

@app.route('/session/status')
async def get_session_status():
    """è·å–å½“å‰ä¼šè¯çŠ¶æ€"""
    try:
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·ID
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨session/statusè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # æ£€æŸ¥ä¼šè¯ç®¡ç†æ˜¯å¦å¯ç”¨
        if not SESSION_MANAGEMENT_AVAILABLE:
            return jsonify({
                'success': True,
                'session_id': user_id,
                'session_management_available': False,
                'message': 'ä¼šè¯ç®¡ç†åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·å‡çº§ Strands Agents åº“',
                'timestamp': datetime.now().isoformat()
            })
        
        # æ£€æŸ¥ä¼šè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        sessions_dir = os.path.join(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')), 'sessions')
        session_dir = os.path.join(sessions_dir, f"session_{user_id}")
        session_exists = os.path.exists(session_dir)
        
        # è·å–ä¼šè¯æ¶ˆæ¯æ•°é‡
        message_count = 0
        if session_exists:
            agents_dir = os.path.join(session_dir, "agents")
            if os.path.exists(agents_dir):
                for agent_dir in os.listdir(agents_dir):
                    messages_dir = os.path.join(agents_dir, agent_dir, "messages")
                    if os.path.exists(messages_dir):
                        message_count = len([f for f in os.listdir(messages_dir) if f.endswith('.json')])
        
        return jsonify({
            'success': True,
            'session_id': user_id,
            'session_management_available': True,
            'session_exists': session_exists,
            'message_count': message_count,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–ä¼šè¯çŠ¶æ€å¤±è´¥: {str(e)}'
        }), 500

@app.route('/memory/recent')
async def get_recent_memories():
    """è·å–æœ€è¿‘çš„è®°å¿†"""
    try:
        limit = int(request.args.get('limit', 10))
        
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨memory/recentè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        memories = user_mem0.get_recent_memories(limit)
        
        return jsonify({
            'success': True,
            'memories': memories,
            'count': len(memories),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–æœ€è¿‘è®°å¿†å¤±è´¥: {str(e)}'
        }), 500

@app.route('/memory/clear', methods=['POST'])
async def clear_memories():
    """æ¸…é™¤æ‰€æœ‰è®°å¿†"""
    try:
        # ä»ä¼šè¯ä¸­è·å–ç”¨æˆ·IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
        user_id = session.get('user_id')
        if not user_id:
            user_id = str(uuid.uuid4())
            session['user_id'] = user_id
            logger.info(f"åœ¨memory/clearè¯·æ±‚ä¸­åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯ID: {user_id}")
        else:
            logger.debug(f"ä½¿ç”¨ç°æœ‰ç”¨æˆ·ä¼šè¯ID: {user_id}")
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        success = user_mem0.clear_user_memories()
        
        if success:
            return jsonify({
                'success': True,
                'message': 'æ‰€æœ‰è®°å¿†å·²æˆåŠŸæ¸…é™¤',
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'success': False,
                'error': 'æ¸…é™¤è®°å¿†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®'
            }), 500
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æ¸…é™¤è®°å¿†å¤±è´¥: {str(e)}'
        }), 500

# æµ‹è¯•æµå¼å“åº”è·¯ç”±å·²ç§»é™¤

@app.route('/health')
async def health():
    """å¥åº·æ£€æŸ¥"""
    try:
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ mem0 å®ä¾‹æ¥æ£€æŸ¥çŠ¶æ€
        temp_mem0 = create_mem0_integration()
        mem0_enabled = temp_mem0.enabled
    except:
        mem0_enabled = False
    
    return jsonify({
        'status': 'healthy',
        'service': 'EMR Upgrade Assistant',
        'mem0_enabled': mem0_enabled,
        'timestamp': datetime.now().isoformat()
    })

@app.errorhandler(404)
async def not_found(error):
    return jsonify({'error': 'Not found'}), 404

@app.errorhandler(500)
async def internal_error(error):
    return jsonify({'error': 'Internal server error'}), 500

# å¯åŠ¨æ–¹å¼æç¤º
if __name__ == '__main__':
    logger.info('è¯·ä½¿ç”¨ hypercorn å¯åŠ¨æ­¤åº”ç”¨ï¼Œä¾‹å¦‚:')
    logger.info('hypercorn emr_upgrade_assistant.app:app --bind 0.0.0.0:5001')