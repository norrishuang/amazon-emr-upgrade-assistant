from quart import Quart, render_template, request, jsonify, Response
import os
import json
import asyncio
from typing import Dict, Any
from dotenv import load_dotenv
import uuid
from datetime import datetime

# æ ¹æ®å®˜æ–¹æ–‡æ¡£å¯¼å…¥ Strands Agents å’Œ MCP ç›¸å…³æ¨¡å—
from mcp import stdio_client, StdioServerParameters
from strands import Agent
from strands.tools.mcp import MCPClient
from mem0_integration import create_mem0_integration
from mem0_tools import mem0_tools
from strands.models import BedrockModel

load_dotenv()

app = Quart(__name__)
app.secret_key = os.getenv('SECRET_KEY', 'emr-upgrade-assistant-secret-key')

# ç¦ç”¨ Quart çš„ç¼“å†²ï¼Œç¡®ä¿æµå¼å“åº”ç«‹å³å‘é€
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0
app.config['TEMPLATES_AUTO_RELOAD'] = True

class EMRUpgradeAssistant:
    """Amazon EMR ç‰ˆæœ¬å‡çº§åŠ©æ‰‹ - åŸºäº Strands Agents"""
    
    def __init__(self):
        try:
            # ä¸åœ¨åˆå§‹åŒ–æ—¶åˆ›å»º mem0 å®ä¾‹ï¼Œè€Œæ˜¯åœ¨æ¯æ¬¡è¯·æ±‚æ—¶åˆ›å»º
            self.mem0 = None
            
            print("ğŸš€ å¼€å§‹åˆå§‹åŒ– EMR å‡çº§åŠ©æ‰‹...")
            
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£é…ç½® MCP å®¢æˆ·ç«¯
            # å‚è€ƒ: https://strandsagents.com/latest/user-guide/concepts/tools/mcp-tools/
            
            # è·å–é¡¹ç›®æ ¹ç›®å½•å’Œ MCP Server ç›®å½•
            project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
            mcp_server_dir = os.path.join(project_root, 'mcp_server')
            
            # æ ¹æ®ä½ æä¾›çš„é…ç½®ï¼Œä½¿ç”¨ uv å‘½ä»¤åˆ›å»º MCP å®¢æˆ·ç«¯
            # é…ç½®æ ¼å¼: {"mcpServers": {"opensearch_mcp_server": {"command": "uv","args": ["--directory","/path/to/mcp_server","run","app.py"]}}}
            self.mcp_client = MCPClient(lambda: stdio_client(
                StdioServerParameters(
                    command="uv",
                    args=["--directory", mcp_server_dir, "run", "app.py"]
                )
            ))
            
            print("âœ… MCP å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            print(f"ğŸ“¡ MCP Server ç›®å½•: {mcp_server_dir}")
            
            # æ³¨æ„ï¼šæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼ŒAgent å¿…é¡»åœ¨ MCP å®¢æˆ·ç«¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­åˆ›å»ºå’Œä½¿ç”¨
            self.agent = None  # å°†åœ¨ process_query ä¸­åˆ›å»º
            
            print("ğŸš€ EMR å‡çº§åŠ©æ‰‹ (Strands Agents) åˆå§‹åŒ–å®Œæˆ")
            
        except ImportError as e:
            print(f"âŒ Strands Agents å¯¼å…¥å¤±è´¥: {str(e)}")
            print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£… Strands Agents:")
            print("pip install strands-agents")
            print("pip install strands-agents-tools")
            print("pip install strands-agents-builder")
            self.agent = None
        except Exception as e:
            print(f"âŒ Agent åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.agent = None
    
    def _get_instructions(self) -> str:
        """è·å– Agent æŒ‡ä»¤"""
        return """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Amazon EMR ç‰ˆæœ¬å‡çº§åŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯ï¼š

1. å¸®åŠ©ç”¨æˆ·äº†è§£ä¸åŒ EMR ç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚å’Œå‡çº§æ³¨æ„äº‹é¡¹
2. æä¾›å„ä¸ªç»„ä»¶ï¼ˆHiveã€Sparkã€Flinkã€HBaseç­‰ï¼‰çš„ç‰ˆæœ¬å…¼å®¹æ€§ä¿¡æ¯
3. è§£ç­”å‡çº§è¿‡ç¨‹ä¸­å¯èƒ½é‡åˆ°çš„æŠ€æœ¯é—®é¢˜
4. æä¾›æœ€ä½³å®è·µå»ºè®®

è¯·å§‹ç»ˆï¼š
- æä¾›å‡†ç¡®ã€è¯¦ç»†çš„æŠ€æœ¯ä¿¡æ¯
- åŸºäºçŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜
- ç»™å‡ºå…·ä½“çš„æ“ä½œå»ºè®®
- çªå‡ºé‡è¦çš„æ³¨æ„äº‹é¡¹å’Œé£é™©ç‚¹
- ä½¿ç”¨ä¸­æ–‡å›ç­”
- ç»“æ„åŒ–å›ç­”ï¼Œä½¿ç”¨æ ‡é¢˜å’Œè¦ç‚¹

å½“ç”¨æˆ·è¯¢é—® EMR å‡çº§ç›¸å…³é—®é¢˜æ—¶ï¼Œè¯·å…ˆä½¿ç”¨ search_context å·¥å…·æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œç„¶ååŸºäºæ£€ç´¢ç»“æœæä¾›ä¸“ä¸šçš„å›ç­”ã€‚

å›ç­”æ ¼å¼å»ºè®®ï¼š
## é—®é¢˜åˆ†æ
## ä¸»è¦å»ºè®®
## å®æ–½æ­¥éª¤
## æ³¨æ„äº‹é¡¹
## ç›¸å…³æ–‡æ¡£
"""
    
    def _extract_content_from_chunk(self, chunk) -> str:
        """ä»æµå¼å“åº”å—ä¸­æå–å†…å®¹"""
        if hasattr(chunk, 'content'):
            return chunk.content
        elif hasattr(chunk, 'text'):
            return chunk.text
        elif isinstance(chunk, str):
            return chunk
        elif hasattr(chunk, 'delta') and hasattr(chunk.delta, 'content'):
            return chunk.delta.content
        elif hasattr(chunk, 'choices') and len(chunk.choices) > 0:
            # OpenAI æ ¼å¼
            choice = chunk.choices[0]
            if hasattr(choice, 'delta') and hasattr(choice.delta, 'content'):
                return choice.delta.content or ""
        else:
            # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            try:
                return str(chunk)
            except:
                return ""
    
    def _format_streaming_content(self, content: str) -> str:
        """æ ¼å¼åŒ–æµå¼å†…å®¹ï¼Œæ·»åŠ é€‚å½“çš„æ¢è¡Œ"""
        import re
        
        # å®šä¹‰éœ€è¦æ¢è¡Œçš„å…³é”®è¯å’Œæ¨¡å¼
        thinking_patterns = [
            r'è®©æˆ‘ä¸ºæ‚¨æ£€ç´¢',
            r'åŸºäºè·å–çš„ä¿¡æ¯',
            r'æˆ‘éœ€è¦è¿›ä¸€æ­¥äº†è§£',
            r'éœ€è¦æ›´å¤šå…³äº',
            r'è®©æˆ‘å†æŸ¥è¯¢',
            r'æ ¹æ®æ£€ç´¢ç»“æœ',
            r'## é—®é¢˜åˆ†æ',
            r'## ä¸»è¦å»ºè®®',
            r'## å®æ–½æ­¥éª¤',
            r'## æ³¨æ„äº‹é¡¹',
            r'## ç›¸å…³æ–‡æ¡£'
        ]
        
        # ä¸ºæ€è€ƒè¿‡ç¨‹æ·»åŠ æ¢è¡Œ
        formatted_content = content
        for pattern in thinking_patterns:
            # åœ¨åŒ¹é…çš„æ¨¡å¼å‰æ·»åŠ æ¢è¡Œï¼ˆå¦‚æœå‰é¢ä¸æ˜¯æ¢è¡Œçš„è¯ï¼‰
            formatted_content = re.sub(
                f'([^\\n])({pattern})', 
                r'\1\n\n\2', 
                formatted_content
            )
        
        # åœ¨å†’å·åæ·»åŠ æ¢è¡Œï¼ˆç”¨äº"å†…å®¹ï¼š"è¿™æ ·çš„æ¨¡å¼ï¼‰
        formatted_content = re.sub(r'ï¼š([^\\n])', r'ï¼š\n\1', formatted_content)
        
        return formatted_content
    
    def _stream_text_output(self, text):
        """å°†æ–‡æœ¬æŒ‰è¯è¯­æµå¼è¾“å‡º - ä¼˜åŒ–ç‰ˆæœ¬"""
        import re
        import time
        
        print(f"ğŸ“ å¼€å§‹æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œå†…å®¹é•¿åº¦: {len(text)}")
        
        # æŒ‰è¯è¯­å’Œæ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼Œä½†æ˜¯ä»¥æ›´å¤§çš„å—ä¸ºå•ä½
        # è¿™æ ·å¯ä»¥çœ‹åˆ°æµå¼æ•ˆæœï¼Œä½†ä¸ä¼šå¤ªæ…¢
        chunks = []
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+|\d+|[^\w\s]|\s+', text)
        
        # å°†å•è¯ç»„åˆæˆæ›´å¤§çš„å—ï¼ˆæ¯3-5ä¸ªè¯ä¸ºä¸€å—ï¼‰
        current_chunk = ""
        for i, word in enumerate(words):
            current_chunk += word
            
            # æ¯3-5ä¸ªè¯æˆ–é‡åˆ°å¥å·ã€æ¢è¡Œç¬¦æ—¶åˆ›å»ºä¸€ä¸ªå—
            if (i + 1) % 4 == 0 or word in ['.', 'ã€‚', '\n', '!', 'ï¼', '?', 'ï¼Ÿ']:
                if current_chunk.strip():
                    chunks.append(current_chunk)
                    current_chunk = ""
        
        # æ·»åŠ å‰©ä½™çš„å†…å®¹
        if current_chunk.strip():
            chunks.append(current_chunk)
        
        accumulated = ""
        
        for chunk in chunks:
            accumulated += chunk
            
            yield {
                "type": "content",
                "content": chunk,
                "accumulated": accumulated,
                "timestamp": datetime.now().isoformat()
            }
            
            # æ·»åŠ é€‚å½“çš„å»¶è¿Ÿæ¥æ¨¡æ‹Ÿæµå¼æ•ˆæœ
            time.sleep(0.1)  # 100ms å»¶è¿Ÿï¼Œè¶³å¤Ÿçœ‹åˆ°æµå¼æ•ˆæœä½†ä¸ä¼šå¤ªæ…¢
    


    
    def process_query_stream_simple(self, user_query: str, user_id: str = None):
        """
        ç®€åŒ–ç‰ˆæµå¼å¤„ç† - ç”¨äºè°ƒè¯•
        """
        try:
            print(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] å¼€å§‹å¤„ç†æŸ¥è¯¢: {user_query}")
            print(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] MCP Client çŠ¶æ€: {self.mcp_client is not None}")
            
            # ç›´æ¥è¿”å›ä¸€ä¸ªæµ‹è¯•å“åº”
            test_response = f"æ”¶åˆ°æ‚¨çš„é—®é¢˜ï¼š{user_query}\n\nè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å“åº”ï¼Œç”¨äºéªŒè¯æµå¼è¾“å‡ºæ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"
            
            print(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] å¼€å§‹æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œå†…å®¹é•¿åº¦: {len(test_response)}")
            
            # æ¨¡æ‹Ÿæµå¼è¾“å‡º
            chunk_count = 0
            for chunk in self._stream_text_output(test_response):
                chunk_count += 1
                print(f"ğŸ”§ [ç®€åŒ–ç‰ˆ] ç”Ÿæˆç¬¬ {chunk_count} ä¸ªæ•°æ®å—: {chunk}")
                yield chunk
            
            print(f"âœ… [ç®€åŒ–ç‰ˆ] æµå¼è¾“å‡ºå®Œæˆï¼Œå…±ç”Ÿæˆ {chunk_count} ä¸ªæ•°æ®å—")
                
        except Exception as e:
            print(f"âŒ [ç®€åŒ–ç‰ˆ] å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            print(f"âŒ [ç®€åŒ–ç‰ˆ] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            yield {
                "type": "error",
                "error": f"ç®€åŒ–ç‰ˆå¤„ç†å¤±è´¥: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

    async def process_query_stream(self, user_query: str, user_id: str = None):
        """
        æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - ä½¿ç”¨ Strands Agent çœŸæ­£çš„æµå¼å“åº”
        ä¿è¯ LLM å†…å®¹å’Œ MCP Server å·¥å…·å†…å®¹éƒ½èƒ½æµå¼è¿”å›åˆ°é¡µé¢ï¼Œå¹¶åœ¨åå°æ‰“å°ã€‚
        """
        if not self.mcp_client:
            yield {
                "type": "error",
                "error": "MCP å®¢æˆ·ç«¯æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥å®‰è£…å’Œé…ç½®",
                "timestamp": datetime.now().isoformat()
            }
            return

        try:
            print(f"ğŸ“ å¼€å§‹æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢: {user_query}")
            with self.mcp_client:
                mcp_tools = self.mcp_client.list_tools_sync()
                all_tools = mcp_tools + mem0_tools
                print(f"ğŸ”§ è·å–åˆ° {len(mcp_tools)} ä¸ª MCP å·¥å…·ï¼Œ{len(mem0_tools)} ä¸ª mem0 å·¥å…·")
                try:
                    bedrock_model = BedrockModel(
                        model_id="us.anthropic.claude-3-5-sonnet-20241022-v2:0",
                        region_name="us-east-1",
                        temperature=0.3,
                    )
                    agent = Agent(
                        tools=all_tools,
                        callback_handler=None,
                        model=bedrock_model
                    )
                    print("âœ… æˆåŠŸåˆ›å»ºä½¿ç”¨ Claude 4.0 Sonnet çš„ Agent")
                except Exception as model_error:
                    print(f"âš ï¸ ä½¿ç”¨ Claude 4.0 Sonnet åˆ›å»º Agent å¤±è´¥: {str(model_error)}")
                    print("å°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹åˆ›å»º Agent")
                    agent = Agent(tools=all_tools, callback_handler=None)
                if hasattr(agent, 'model') and hasattr(agent.model, 'config'):
                    print(f"ğŸ”§ ä½¿ç”¨æ¨¡å‹é…ç½®: {agent.model.config}")
                else:
                    print("âš ï¸ æ— æ³•è·å–æ¨¡å‹é…ç½®ä¿¡æ¯")
                user_mem0 = create_mem0_integration(user_id)
                from mem0_tools import set_current_user_mem0
                set_current_user_mem0(user_mem0)
                historical_context = user_mem0.get_context_for_query(user_query)
                system_instructions = self._get_instructions()
                if historical_context:
                    full_query = f"{system_instructions}\n\n{historical_context}\n\nç”¨æˆ·é—®é¢˜: {user_query}"
                    print(f"ğŸ“š æ·»åŠ äº†å†å²ä¸Šä¸‹æ–‡ï¼Œé•¿åº¦: {len(historical_context)}")
                else:
                    full_query = f"{system_instructions}\n\nç”¨æˆ·é—®é¢˜: {user_query}"
                print(f"ğŸ”§ å¼€å§‹ Strands Agent æµå¼è°ƒç”¨...")
                accumulated_response = ""
                async def async_stream():
                    nonlocal accumulated_response
                    try:
                        async for event in agent.stream_async(full_query):
                            # æ³¨é‡Šæ‰ MCP Server æŸ¥è¯¢è¿”å›çš„æ—¥å¿—æ‰“å°
                            # print("Agent event:", event)  # æ‰“å°æ‰€æœ‰ event
                            # LLM å†…å®¹æµå¼è¿”å›
                            if "data" in event:
                                content = event["data"]
                                if content:
                                    accumulated_response += content
                                    print(f"ğŸ“ LLMæµå¼å†…å®¹: {content}")
                                    yield {
                                        "type": "content",
                                        "content": content,
                                        "accumulated": accumulated_response,
                                        "timestamp": datetime.now().isoformat()
                                    }
                            # å·¥å…·è°ƒç”¨äº‹ä»¶
                            if "current_tool_use" in event and event["current_tool_use"].get("name"):
                                tool_name = event["current_tool_use"]["name"]
                                print(f"ğŸ”§ å·¥å…·è°ƒç”¨: {tool_name}")
                                yield {
                                    "type": "status",
                                    "message": f"[ä½¿ç”¨å·¥å…·: {tool_name}]",
                                    "timestamp": datetime.now().isoformat()
                                }
                            # MCP Server å·¥å…·è¿”å›å†…å®¹ - å…³é—­æ—¥å¿—æ‰“å°
                            if "tool_response" in event and event["tool_response"]:
                                # print(f"ğŸŸ¢ MCP Server å·¥å…·è¿”å›å†…å®¹: {event['tool_response']}")
                                pass
                    except Exception as e:
                        print(f"âŒ å¼‚æ­¥æµå¼è°ƒç”¨å¤±è´¥: {str(e)}")
                        yield {
                            "type": "error",
                            "error": str(e),
                            "timestamp": datetime.now().isoformat()
                        }
                async for chunk in async_stream():
                    yield chunk
                if accumulated_response:
                    try:
                        user_mem0.add_memory(
                            message="EMRå‡çº§å’¨è¯¢å¯¹è¯",
                            user_query=user_query,
                            response=accumulated_response,
                            metadata={
                                "user_id": user_id,
                                "response_length": len(accumulated_response)
                            }
                        )
                        print("ğŸ’¾ å¯¹è¯è®°å¿†å·²ä¿å­˜åˆ° mem0")
                    except Exception as mem_error:
                        print(f"âš ï¸ ä¿å­˜è®°å¿†å¤±è´¥: {str(mem_error)}")
        except Exception as e:
            print(f"âŒ æµå¼å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")
            yield {
                "type": "error",
                "error": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

    async def process_query(self, user_query: str, user_id: str = None) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢å†…å®¹
            user_id: ç”¨æˆ·ID
            
        Returns:
            åŒ…å«å›ç­”å’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
        """
        if not self.mcp_client:
            return {
                "success": False,
                "error": "MCP å®¢æˆ·ç«¯æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥å®‰è£…å’Œé…ç½®",
                "timestamp": datetime.now().isoformat()
            }
        
        try:
            print(f"ğŸ“ å¤„ç†ç”¨æˆ·æŸ¥è¯¢: {user_query}")
            
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå¿…é¡»åœ¨ MCP å®¢æˆ·ç«¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­ä½¿ç”¨ Agent
            with self.mcp_client:
                # è·å– MCP æœåŠ¡å™¨æä¾›çš„å·¥å…·
                tools = self.mcp_client.list_tools_sync()
                print(f"ğŸ”§ è·å–åˆ° {len(tools)} ä¸ª MCP å·¥å…·")
                
                # åœ¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­åˆ›å»º Agent
                # æ ¹æ® Strands Agents APIï¼ŒAgent åˆå§‹åŒ–ä¸æ¥å— instructions å‚æ•°
                agent = Agent(tools=tools)
                
                # æ„å»ºåŒ…å«ç³»ç»ŸæŒ‡ä»¤çš„å®Œæ•´æŸ¥è¯¢
                system_instructions = self._get_instructions()
                full_query = f"{system_instructions}\n\nç”¨æˆ·é—®é¢˜: {user_query}"
                
                # ä½¿ç”¨ Agent å¤„ç†æŸ¥è¯¢
                response = agent(full_query)
                
                print("âœ… Strands Agent å¤„ç†å®Œæˆ")
                
                # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå“åº”æ ¼å¼å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡
                if isinstance(response, str):
                    answer = response
                    tools_used = []
                else:
                    answer = getattr(response, 'content', str(response))
                    tools_used = getattr(response, 'tools_used', [])
                
                return {
                    "success": True,
                    "answer": answer,
                    "tools_used": tools_used,
                    "query": user_query,
                    "timestamp": datetime.now().isoformat()
                }
            
        except Exception as e:
            print(f"âŒ å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")
            return {
                "success": False,
                "error": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

# åˆå§‹åŒ–åŠ©æ‰‹
emr_assistant = EMRUpgradeAssistant()

@app.route('/')
async def index():
    """ä¸»é¡µ"""
    return await render_template('index.html')

@app.route('/chat', methods=['POST'])
async def chat_stream():
    """å¤„ç†èŠå¤©è¯·æ±‚ - æµå¼å“åº”"""
    try:
        data = await request.get_json()
        user_query = data.get('query', '').strip()
        
        if not user_query:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥æ‚¨çš„é—®é¢˜'
            }), 400
        
        # ä¸´æ—¶å»æ‰ sessionï¼Œç›´æ¥ç”¨éšæœº user_id
        import uuid
        user_id = str(uuid.uuid4())
        
        # è¿”å›æµå¼å“åº” - å¼ºåˆ¶å®æ—¶ä¼ è¾“ï¼Œæ·»åŠ å¡«å……æ•°æ®
        async def generate_stream():
            import sys
            import os
            
            # å¼ºåˆ¶ç¦ç”¨ Python çš„è¾“å‡ºç¼“å†²
            os.environ['PYTHONUNBUFFERED'] = '1'
            
            try:
                print("ğŸ”„ å¼€å§‹ç”Ÿæˆæµå¼å“åº”...")
                
                # ç«‹å³å‘é€å¿ƒè·³å’Œå¡«å……æ•°æ®ï¼Œå¼ºåˆ¶å»ºç«‹è¿æ¥
                heartbeat = json.dumps({'type': 'heartbeat'})
                yield f"data: {heartbeat}\n\n"
                
                # å‘é€å¡«å……æ•°æ®ï¼Œå¼ºåˆ¶ Flask ç«‹å³å‘é€å“åº”å¤´
                padding = " " * 1024  # 1KB å¡«å……æ•°æ®
                yield f": padding {padding}\n\n"
                
                print("ğŸ“¡ å¿ƒè·³å’Œå¡«å……æ•°æ®å·²å‘é€ï¼Œå¼€å§‹å¤„ç†æŸ¥è¯¢...")
                
                # å…ˆå‘é€ä¸€ä¸ªåˆå§‹å†…å®¹ï¼Œç¡®ä¿å‰ç«¯èƒ½ç«‹å³æ˜¾ç¤º
                initial_content = {
                    "type": "content",
                    "content": "æ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜...\n\n",
                    "accumulated": "æ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜...\n\n",
                    "timestamp": datetime.now().isoformat()
                }
                yield f"data: {json.dumps(initial_content, ensure_ascii=False)}\n\n"
                yield f": initial-content\n\n"
                
                # ä½¿ç”¨å®Œæ•´çš„ Strands Agent æµå¼å¤„ç†
                chunk_count = 0
                async for chunk in emr_assistant.process_query_stream(user_query, user_id):
                    chunk_count += 1
                    print(f"ç”Ÿæˆç¬¬ {chunk_count} ä¸ªæ•°æ®å—: {chunk}")
                    
                    # ç¡®ä¿ JSON åºåˆ—åŒ–ä¸ä¼šå¤±è´¥
                    try:
                        chunk_data = json.dumps(chunk, ensure_ascii=False)
                    except Exception as json_err:
                        print(f"JSON åºåˆ—åŒ–å¤±è´¥: {str(json_err)}, å°è¯•ç®€åŒ–æ•°æ®")
                        # å¦‚æœåºåˆ—åŒ–å¤±è´¥ï¼Œå°è¯•ç®€åŒ–æ•°æ®
                        simplified_chunk = {
                            "type": chunk.get("type", "content"),
                            "content": str(chunk.get("content", "")),
                            "timestamp": datetime.now().isoformat()
                        }
                        chunk_data = json.dumps(simplified_chunk, ensure_ascii=False)
                    
                    # ç«‹å³å‘é€æ•°æ®ï¼Œç¡®ä¿æ¯ä¸ªå—éƒ½æœ‰å®Œæ•´çš„ SSE æ ¼å¼
                    yield f"data: {chunk_data}\n\n"
                    
                    # æ·»åŠ å°çš„å¡«å……æ•°æ®ç¡®ä¿ç«‹å³ä¼ è¾“
                    yield f": chunk-{chunk_count}\n\n"
                    
                    # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
                    sys.stdout.flush()
                    sys.stderr.flush()
                
                # å‘é€ç»“æŸä¿¡å·
                end_data = json.dumps({'type': 'end'})
                yield f"data: {end_data}\n\n"
                
                print(f"âœ… æµå¼å“åº”å®Œæˆï¼Œå…±å‘é€ {chunk_count} ä¸ªæ•°æ®å—")
                
            except Exception as e:
                import traceback
                print(f"âŒ æµå¼å“åº”é”™è¯¯: {str(e)}")
                print(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                error_data = json.dumps({'type': 'error', 'error': str(e)})
                yield f"data: {error_data}\n\n"
        
        return Response(generate_stream(), content_type='text/event-stream')
        
    except Exception as e:
        import traceback
        print(f"âŒ å¤„ç†èŠå¤©è¯·æ±‚å¤±è´¥: {str(e)}")
        print(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        return jsonify({
            'success': False,
            'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/chat-sync', methods=['POST'])
async def chat_sync():
    """å¤„ç†èŠå¤©è¯·æ±‚ - åŒæ­¥å“åº”ï¼ˆå¤‡ç”¨ï¼‰"""
    try:
        data = await request.get_json()
        user_query = data.get('query', '').strip()
        
        if not user_query:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥æ‚¨çš„é—®é¢˜'
            }), 400
        
        # è·å–æˆ–åˆ›å»ºç”¨æˆ·ä¼šè¯ID
        user_id = str(uuid.uuid4())
        
        # å¤„ç†æŸ¥è¯¢
        result = await emr_assistant.process_query(user_query, user_id)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/memory/stats')
async def memory_stats():
    """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
    try:
        # è·å–æˆ–åˆ›å»ºç”¨æˆ·ä¼šè¯ID
        user_id = str(uuid.uuid4())
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        stats = user_mem0.get_memory_stats()
        
        return jsonify({
            'success': True,
            'stats': stats,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–è®°å¿†ç»Ÿè®¡å¤±è´¥: {str(e)}'
        }), 500

@app.route('/memory/search', methods=['POST'])
async def search_memories():
    """æœç´¢å†å²è®°å¿†"""
    try:
        data = await request.get_json()
        query = data.get('query', '').strip()
        limit = data.get('limit', 5)
        
        if not query:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥æœç´¢æŸ¥è¯¢'
            }), 400
        
        # è·å–æˆ–åˆ›å»ºç”¨æˆ·ä¼šè¯ID
        user_id = str(uuid.uuid4())
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        memories = user_mem0.search_memories(query, limit)
        
        return jsonify({
            'success': True,
            'memories': memories,
            'query': query,
            'count': len(memories),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æœç´¢è®°å¿†å¤±è´¥: {str(e)}'
        }), 500

@app.route('/memory/recent')
async def get_recent_memories():
    """è·å–æœ€è¿‘çš„è®°å¿†"""
    try:
        limit = int(request.args.get('limit', 10))
        
        # è·å–æˆ–åˆ›å»ºç”¨æˆ·ä¼šè¯ID
        user_id = str(uuid.uuid4())
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        memories = user_mem0.get_recent_memories(limit)
        
        return jsonify({
            'success': True,
            'memories': memories,
            'count': len(memories),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–æœ€è¿‘è®°å¿†å¤±è´¥: {str(e)}'
        }), 500

@app.route('/memory/clear', methods=['POST'])
async def clear_memories():
    """æ¸…é™¤æ‰€æœ‰è®°å¿†"""
    try:
        # è·å–æˆ–åˆ›å»ºç”¨æˆ·ä¼šè¯ID
        user_id = str(uuid.uuid4())
        
        # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»º mem0 å®ä¾‹
        user_mem0 = create_mem0_integration(user_id)
        success = user_mem0.clear_user_memories()
        
        if success:
            return jsonify({
                'success': True,
                'message': 'æ‰€æœ‰è®°å¿†å·²æˆåŠŸæ¸…é™¤',
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'success': False,
                'error': 'æ¸…é™¤è®°å¿†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®'
            }), 500
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æ¸…é™¤è®°å¿†å¤±è´¥: {str(e)}'
        }), 500

@app.route('/test-stream')
async def test_stream():
    """æµ‹è¯•æµå¼å“åº” - æœ€ç®€å•çš„ç‰ˆæœ¬"""
    async def generate_test_stream():
        import asyncio
        yield f"data: {json.dumps({'type': 'heartbeat'})}\n\n"
        test_messages = [
            "è¿™æ˜¯ç¬¬ä¸€æ¡æµ‹è¯•æ¶ˆæ¯",
            "è¿™æ˜¯ç¬¬äºŒæ¡æµ‹è¯•æ¶ˆæ¯",
            "è¿™æ˜¯ç¬¬ä¸‰æ¡æµ‹è¯•æ¶ˆæ¯",
            "æµå¼å“åº”æµ‹è¯•å®Œæˆï¼"
        ]
        for i, msg in enumerate(test_messages):
            chunk_data = {
                "type": "content",
                "content": msg,
                "accumulated": " ".join(test_messages[:i+1]),
                "timestamp": datetime.now().isoformat()
            }
            yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
            await asyncio.sleep(0.5)
        yield f"data: {json.dumps({'type': 'end'})}\n\n"
    return Response(generate_test_stream(), content_type='text/event-stream')

@app.route('/health')
async def health():
    """å¥åº·æ£€æŸ¥"""
    try:
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ mem0 å®ä¾‹æ¥æ£€æŸ¥çŠ¶æ€
        temp_mem0 = create_mem0_integration()
        mem0_enabled = temp_mem0.enabled
    except:
        mem0_enabled = False
    
    return jsonify({
        'status': 'healthy',
        'service': 'EMR Upgrade Assistant',
        'mem0_enabled': mem0_enabled,
        'timestamp': datetime.now().isoformat()
    })

@app.errorhandler(404)
async def not_found(error):
    return jsonify({'error': 'Not found'}), 404

@app.errorhandler(500)
async def internal_error(error):
    return jsonify({'error': 'Internal server error'}), 500

# å¯åŠ¨æ–¹å¼æç¤º
if __name__ == '__main__':
    print('è¯·ä½¿ç”¨ hypercorn å¯åŠ¨æ­¤åº”ç”¨ï¼Œä¾‹å¦‚:')
    print('hypercorn emr_upgrade_assistant.app:app --bind 0.0.0.0:5001')