AWSTemplateFormatVersion: '2010-09-09'
Description: 'CloudFormation template for OpenSearch ML Connector with DeepSeek and Titan Embedding models'

Parameters:
  OpenSearchDomainName:
    Type: String
    Description: Name of the OpenSearch domain
    Default: deepseek-demo
  
  OpenSearchDomainEndpoint:
    Type: String
    Description: Full endpoint URL for the OpenSearch domain (e.g., https://search-domain.region.es.amazonaws.com.cn)
    
  OpenSearchCredentialsSecretName:
    Type: String
    Description: Name of the Secrets Manager secret containing OpenSearch credentials
    Default: opensearch_credentials
    
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: VPC where the EC2 instance will be launched
    
  SubnetId:
    Type: AWS::EC2::Subnet::Id
    Description: Subnet where the EC2 instance will be launched
    
  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: Name of an existing EC2 KeyPair to enable SSH access to the instance
    
  InstanceSecurityGroup:
    Type: AWS::EC2::SecurityGroup::Id
    Description: Security group ID for the EC2 instance (leave empty to create a new one)
  
  LLMModelId:
    Type: String
    Description: ID of the DeepSeek LLM model in Amazon Bedrock
    Default: us.deepseek.r1-v1:0
  
  Region:
    Type: String
    Description: AWS Region
    Default: us-east-1
    
  DependenciesS3Bucket:
    Type: String
    Description: S3 bucket containing the Lambda layer dependencies zip file
    
  DependenciesS3Key:
    Type: String
    Description: S3 key for the Lambda layer dependencies zip file

Conditions:
  CreateSecurityGroup: !Equals [!Ref InstanceSecurityGroup, ""]

Mappings:
  RegionMap:
    us-east-1:
      AMI: ami-0e8a34246278c21e4  # Amazon Linux 2023 AMI
    us-east-2:
      AMI: ami-07a7a8c10c60f25be
    us-west-1:
      AMI: ami-0ce2cb35386fc22e9
    us-west-2:
      AMI: ami-05f9478b4deb8d173
    ap-northeast-1:
      AMI: ami-0f8048fa3e3b9e8ff
    ap-northeast-2:
      AMI: ami-0f3a440bbcff3d043
    ap-southeast-1:
      AMI: ami-0df7a207adb9748c7
    ap-southeast-2:
      AMI: ami-0310483fb2b488153
    eu-central-1:
      AMI: ami-0faab6bdbac9486fb
    eu-west-1:
      AMI: ami-0e309a5f3a6dd97ea
    eu-west-2:
      AMI: ami-0b1b3a0c66d750e27
    sa-east-1:
      AMI: ami-0a0b913ef3249633d
    cn-north-1:
      AMI: ami-0b4d5e4d0d9c7f79e
    cn-northwest-1:
      AMI: ami-0b4d5e4d0d9c7f79e

Resources:
  # Add a Lambda execution role policy for PassRole
  LambdaPassRolePolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Description: Policy to allow Lambda to pass roles
      ManagedPolicyName: !Sub "lambda-pass-role-policy-${AWS::StackName}"
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - iam:GetRole
              - iam:PassRole
            Resource: 
              - !Sub 'arn:aws:iam::${AWS::AccountId}:role/invoke-deepseek-role-*'
              - !Sub 'arn:aws:iam::${AWS::AccountId}:role/create-deepseek-connector-role-*'

  InvokeDeepSeekPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Description: Policy to allow invoking Bedrock models for DeepSeek and Titan embedding
      ManagedPolicyName: !Sub "invoke-deepseek-policy-${AWS::StackName}"
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - bedrock:InvokeModel
            Resource:
              - !Sub 'arn:aws:bedrock:${Region}::foundation-model/${LLMModelId}'
              - !Sub 'arn:aws:bedrock:${Region}::foundation-model/amazon.titan-embed-text-v2:0'

  InvokeDeepSeekRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "invoke-deepseek-role-${AWS::StackName}"
      Description: Role for OpenSearch to invoke Bedrock models
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: 
                - es.amazonaws.com
                - aoss.amazonaws.com
            Action: sts:AssumeRole
          - Effect: Allow
            Principal:
              AWS: !Sub 'arn:aws:iam::${AWS::AccountId}:root'
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - !Ref InvokeDeepSeekPolicy

  # 2. IAM Role for creating ML connectors in OpenSearch
  CreateDeepSeekConnectorPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Description: Policy to allow creating ML connectors in OpenSearch
      ManagedPolicyName: !Sub "create-deepseek-connector-policy-${AWS::StackName}"
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action: iam:PassRole
            Resource: !GetAtt InvokeDeepSeekRole.Arn
          - Effect: Allow
            Action: es:ESHttpPost
            Resource: !Sub 'arn:aws:es:${Region}:${AWS::AccountId}:domain/${OpenSearchDomainName}'

  CreateDeepSeekConnectorRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "create-deepseek-connector-role-${AWS::StackName}"
      Description: Role for creating ML connectors in OpenSearch
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: 
                - lambda.amazonaws.com
                - es.amazonaws.com
                - aoss.amazonaws.com
            Action: sts:AssumeRole
          - Effect: Allow
            Principal:
              AWS: !Sub 'arn:aws:iam::${AWS::AccountId}:root'
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - !Ref CreateDeepSeekConnectorPolicy

  # 3. Lambda function to configure OpenSearch security and create ML connectors
  OpenSearchConfigurationLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "opensearch-config-lambda-role-${AWS::StackName}"
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - !Ref LambdaPassRolePolicy
      Policies:
        - PolicyName: OpenSearchAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - es:ESHttpGet
                  - es:ESHttpPost
                  - es:ESHttpPut
                Resource: !Sub 'arn:aws:es:${Region}:${AWS::AccountId}:domain/${OpenSearchDomainName}/*'
        - PolicyName: STSAssumeRole
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - sts:AssumeRole
                Resource: "*"
        - PolicyName: IAMPassRole
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - iam:PassRole
                Resource: 
                  - !Sub 'arn:aws:iam::${AWS::AccountId}:role/invoke-deepseek-role-${AWS::StackName}'
                  - !Sub 'arn:aws:iam::${AWS::AccountId}:role/create-deepseek-connector-role-${AWS::StackName}'
                  - !GetAtt InvokeDeepSeekRole.Arn
        - PolicyName: LambdaAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - lambda:GetFunction
                Resource: !Sub 'arn:aws:lambda:${Region}:${AWS::AccountId}:function:${AWS::StackName}-OpenSearchConfig'
        - PolicyName: SecretsManagerAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                  - secretsmanager:DescribeSecret
                Resource: 
                  - !Sub 'arn:aws:secretsmanager:${Region}:${AWS::AccountId}:secret:${OpenSearchCredentialsSecretName}*'

  # Add a resource-based policy to allow PassRole to the InvokeDeepSeekRole
  InvokeDeepSeekRolePolicy:
    Type: AWS::IAM::Policy
    DependsOn: 
      - OpenSearchConfigurationLambdaRole
      - InvokeDeepSeekRole
    Properties:
      PolicyName: !Sub "invoke-deepseek-role-policy-${AWS::StackName}"
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action: 
              - iam:PassRole
              - iam:GetRole
            Resource: 
              - !GetAtt InvokeDeepSeekRole.Arn
              - !Sub 'arn:aws:iam::${AWS::AccountId}:role/invoke-deepseek-role-${AWS::StackName}'
      Roles:
        - !Ref OpenSearchConfigurationLambdaRole

  # Lambda Layer for Python dependencies
  PythonDependenciesLayer:
    Type: AWS::Lambda::LayerVersion
    Properties:
      CompatibleRuntimes:
        - python3.9
      Content:
        S3Bucket: !Ref DependenciesS3Bucket
        S3Key: !Ref DependenciesS3Key
      Description: Layer containing Python dependencies for OpenSearch ML Connector
      LayerName: !Sub "opensearch-ml-connector-deps-${AWS::StackName}"

  OpenSearchConfigurationLambda:
    Type: AWS::Lambda::Function
    DependsOn:
      - OpenSearchConfigurationLambdaRole
      - InvokeDeepSeekRole
      - CreateDeepSeekConnectorRole
      - InvokeDeepSeekRolePolicy
    Properties:
      FunctionName: !Sub "${AWS::StackName}-OpenSearchConfig"
      Handler: index.handler
      Role: !GetAtt OpenSearchConfigurationLambdaRole.Arn
      Runtime: python3.9
      Timeout: 300
      Layers:
        - !Ref PythonDependenciesLayer
      Environment:
        Variables:
          OPENSEARCH_DOMAIN_ENDPOINT: !Ref OpenSearchDomainEndpoint
          OPENSEARCH_CREDENTIALS_SECRET_NAME: !Ref OpenSearchCredentialsSecretName
          REGION: !Ref Region
          BEDROCK_REGION: !Ref Region
          INVOKE_DEEPSEEK_ROLE_ARN: !GetAtt InvokeDeepSeekRole.Arn
          CREATE_DEEPSEEK_CONNECTOR_ROLE_ARN: !GetAtt CreateDeepSeekConnectorRole.Arn
          LLM_MODEL_ID: !Ref LLMModelId
          ACCOUNT_ID: !Ref AWS::AccountId
          AWS_CLOUDFORMATION_STACK_NAME: !Ref AWS::StackName
      Code:
        ZipFile: |
          import boto3
          import json
          import os
          import requests
          from requests_aws4auth import AWS4Auth
          import time
          import urllib3
          import logging
          
          # Configure logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          
          # 内联 cfnresponse 模块
          SUCCESS = "SUCCESS"
          FAILED = "FAILED"
          http = urllib3.PoolManager()
          
          def send_cfn_response(event, context, responseStatus, responseData, physicalResourceId=None, noEcho=False, reason=None):
              responseUrl = event['ResponseURL']
              logger.info(f"CFN response URL: {responseUrl}")
              
              responseBody = {
                  'Status': responseStatus,
                  'Reason': reason or "See the details in CloudWatch Log Stream: {}".format(context.log_stream_name),
                  'PhysicalResourceId': physicalResourceId or context.log_stream_name,
                  'StackId': event['StackId'],
                  'RequestId': event['RequestId'],
                  'LogicalResourceId': event['LogicalResourceId'],
                  'NoEcho': noEcho,
                  'Data': responseData
              }
              
              json_responseBody = json.dumps(responseBody)
              logger.info(f"Response body: {json_responseBody}")
              
              headers = {
                  'content-type': '',
                  'content-length': str(len(json_responseBody))
              }
              
              try:
                  response = http.request('PUT', responseUrl, headers=headers, body=json_responseBody)
                  logger.info(f"Status code: {response.status}")
              except Exception as e:
                  logger.error(f"send(..) failed executing http.request(..): {e}")

          def handler(event, context):
              # For CloudFormation custom resource
              responseData = {}
              
              # Log the event for debugging
              logger.info(f"Received event: {json.dumps(event)}")
              
              # Check if this is a CloudFormation delete event
              if event.get('RequestType') == 'Delete':
                  logger.info("Processing Delete request")
                  send_cfn_response(event, context, SUCCESS, responseData)
                  return
              
              try:
                  # Get environment variables
                  opensearch_endpoint = os.environ['OPENSEARCH_DOMAIN_ENDPOINT']
                  region = os.environ['REGION']
                  bedrock_region = os.environ['BEDROCK_REGION']
                  invoke_role_arn = os.environ['INVOKE_DEEPSEEK_ROLE_ARN']
                  create_connector_role_arn = os.environ['CREATE_DEEPSEEK_CONNECTOR_ROLE_ARN']
                  llm_model_id = os.environ['LLM_MODEL_ID']
                  account_id = os.environ['ACCOUNT_ID']
                  secret_name = os.environ['OPENSEARCH_CREDENTIALS_SECRET_NAME']
                  
                  logger.info(f"OpenSearch endpoint: {opensearch_endpoint}")
                  logger.info(f"Region: {region}")
                  logger.info(f"Bedrock Region: {bedrock_region}")
                  logger.info(f"LLM model ID: {llm_model_id}")
                  logger.info(f"Secret name: {secret_name}")
                  
                  # Get OpenSearch credentials from Secrets Manager
                  logger.info("Getting OpenSearch credentials from Secrets Manager")
                  secrets_client = boto3.client('secretsmanager', region_name=region)
                  secret_response = secrets_client.get_secret_value(SecretId=secret_name)
                  secret = json.loads(secret_response['SecretString'])
                  admin_user = secret.get('username')
                  admin_password = secret.get('password')
                  
                  if not admin_user or not admin_password:
                      raise Exception(f"Secret {secret_name} does not contain username and password keys")
                  
                  logger.info(f"Successfully retrieved OpenSearch credentials for user: {admin_user}")
                  
                  # Set up authentication
                  userauth = (admin_user, admin_password)
                  headers = {"Content-Type": "application/json"}
                  
                  # Disable SSL warnings - not recommended for production
                  urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
                  
                  # 1. Configure OpenSearch security - Add role mapping
                  logger.info("Configuring OpenSearch security - Adding role mapping")
                  lambda_invoke_ml_commons_role_name = 'LambdaInvokeOpenSearchMLCommonsRole'
                  lambda_invoke_ml_commons_role_arn = f'arn:aws:iam::{account_id}:role/{lambda_invoke_ml_commons_role_name}'
                  
                  # Add the Lambda execution role to the role mapping using a reliable method
                  try:
                      # Get the Lambda execution role using the Lambda API
                      lambda_client = boto3.client('lambda')
                      function_name = os.environ['AWS_LAMBDA_FUNCTION_NAME']
                      response = lambda_client.get_function(FunctionName=function_name)
                      lambda_role_arn = response['Configuration']['Role']
                      lambda_execution_role = lambda_role_arn.split('/')[-1]
                      logger.info(f"Lambda execution role name: {lambda_execution_role}")
                      logger.info(f"Lambda execution role ARN: {lambda_role_arn}")
                  except Exception as e:
                      # Fallback method if the above fails
                      logger.warning(f"Error getting Lambda role via API: {str(e)}")
                      lambda_execution_role = os.environ.get('AWS_LAMBDA_FUNCTION_NAME', 'unknown') + '-role'
                      lambda_role_arn = f"arn:aws:iam::{account_id}:role/{lambda_execution_role}"
                      logger.info(f"Using fallback Lambda role: {lambda_role_arn}")
                  
                  role_mapping = {
                      "backend_roles": [
                          create_connector_role_arn,
                          lambda_invoke_ml_commons_role_arn,
                          lambda_role_arn,
                          # Add the OpenSearch Configuration Lambda role explicitly
                          f"arn:aws:iam::{account_id}:role/opensearch-config-lambda-role-{os.environ.get('AWS_CLOUDFORMATION_STACK_NAME', '')}"
                      ]
                  }
                  
                  try:
                      response = requests.put(
                          f"{opensearch_endpoint}/_plugins/_security/api/rolesmapping/all_access",
                          auth=userauth,
                          json=role_mapping,
                          headers=headers,
                          verify=False  # In production, use proper certificate verification
                      )
                      logger.info(f"Role mapping response: {response.status_code} - {response.text}")
                      if response.status_code >= 400:
                          raise Exception(f"Failed to configure role mapping: {response.text}")
                  except Exception as e:
                      logger.error(f"Error configuring role mapping: {str(e)}")
                      raise e
                  
                  # 3. Create AWS4Auth for connector creation
                  logger.info("Creating AWS4Auth for connector creation")
                  try:
                      # Use the Lambda's own credentials instead of assuming a role
                      session = boto3.Session()
                      credentials = session.get_credentials()

                      awsauth = AWS4Auth(
                          credentials.access_key,
                          credentials.secret_key,
                          region,
                          'es',
                          session_token=credentials.token
                      )

                      # Log the identity for debugging
                      sts_client = boto3.client('sts')
                      identity = sts_client.get_caller_identity()
                      logger.info(f"Current identity: {json.dumps(identity)}")

                      # Add explicit PassRole permission check
                      try:
                          iam_client = boto3.client('iam')
                          logger.info(f"Checking PassRole permissions for role: {invoke_role_arn}")
                          iam_client.get_role(RoleName=invoke_role_arn.split('/')[-1])
                          logger.info("Successfully retrieved role information")
                      except Exception as e:
                          logger.error(f"Error checking role permissions: {str(e)}")
                          logger.info("Continuing despite permission check error...")

                  except Exception as e:
                      logger.error(f"Error creating AWS4Auth: {str(e)}")
                      raise e
                  
                  # 4. Create DeepSeek LLM Connector using ML Commons
                  logger.info("Creating DeepSeek LLM Connector using ML Commons")
                  
                  # Create the connector directly without checking if it exists
                  connector_payload = {
                      "name": "deepseek-connector",
                      "description": "Connector for DeepSeek model via Amazon Bedrock",
                      "version": "1",
                      "protocol": "aws_sigv4",
                      "parameters": {
                          "region": bedrock_region,
                          "service_name": "bedrock",
                          "action": "invoke-model",
                          "model_id": llm_model_id,
                          "content_type": "application/json",
                          "request_body": "{\"prompt\": \"${parameters.prompt}\", \"max_tokens\": ${parameters.max_tokens}, \"temperature\": ${parameters.temperature}}",
                          "response_body": "$.generation"
                      },
                      "credential": {
                          "roleArn": invoke_role_arn
                      },
                      "actions": [
                          {
                              "action_type": "predict",
                              "method": "POST",
                              "url": f"https://bedrock-runtime.{bedrock_region}.amazonaws.com/model/${{parameters.model_id}}/invoke",
                              "headers": {
                                  "content-type": "${parameters.content_type}"
                              },
                              "request_body": "${parameters.request_body}",
                              "pre_process_function": "connector.pre_process.bedrock",
                              "post_process_function": "connector.post_process.bedrock"
                          }
                      ]
                  }
                  
                  try:
                      response = requests.post(
                          f"{opensearch_endpoint}/_plugins/_ml/connectors/_create",
                          auth=awsauth,
                          json=connector_payload,
                          headers=headers,
                          verify=False
                      )
                      logger.info(f"Create DeepSeek connector response: {response.status_code} - {response.text}")
                      if response.status_code >= 400:
                          raise Exception(f"Failed to Create DeepSeek connector: {response.text}")
                      
                      logger.info("Successfully registered DeepSeek connector")
                      deepseek_connector_id = json.loads(response.text)['connector_id']
                  except Exception as e:
                      logger.error(f"Error creating DeepSeek connector: {str(e)}")
                      # Continue even if there's an error, as the connector might already exist
                      logger.info("Continuing with connector search...")
                      
                  try:
                      # Create model from connector
                      model_payload = {
                          "name": "Bedrock DeepSeek R1 model",
                          "function_name": "remote",
                          "description": "DeepSeek LLM model via Amazon Bedrock",
                          "connector_id": deepseek_connector_id
                      }
                      
                      response = requests.post(
                          f"{opensearch_endpoint}/_plugins/_ml/models/_register",
                          auth=awsauth,
                          json=model_payload,
                          headers=headers,
                          verify=False
                      )
                      logger.info(f"Register DeepSeek model response: {response.status_code} - {response.text}")
                    
                      deepseek_model_id = response.json()['model_id']

                      if not deepseek_model_id:
                          raise Exception("Could not find DeepSeek model ID after registration")
                      
                      responseData['deepseekModelId'] = deepseek_model_id
                      responseData['deepseekConnectorId'] = deepseek_connector_id
                      logger.info(f"DeepSeek model ID: {deepseek_model_id}")
                      logger.info(f"DeepSeek connector ID: {deepseek_connector_id}")
          
          
                      # Deploy DeepSeek model
                      response = requests.post(
                          f"{opensearch_endpoint}/_plugins/_ml/models/{deepseek_model_id}/_deploy",
                          auth=awsauth,
                          headers=headers,
                          verify=False
                      )
                      logger.info(f"DeepSeek model deploy response: {response.status_code} - {response.text}")
                      if response.status_code >= 400:
                          raise Exception(f"Failed to deploy DeepSeek model: {response.text}")
          
          
                  except Exception as e:
                      logger.error(f"Error creating DeepSeek integration: {str(e)}")
                      raise e
                  
                  # 5. Create Titan Embedding Connector using ML Commons
                  logger.info("Creating Titan Embedding Connector using ML Commons")
                  
                  # Create the connector directly without checking if it exists
                  connector_payload = {
                      "name": "titan-embedding-connector",
                      "description": "Connector for Titan Embedding model via Amazon Bedrock",
                      "version": "1",
                      "protocol": "aws_sigv4",
                      "parameters": {
                          "region": region,
                          "service_name": "bedrock",
                          "action": "invoke-model",
                          "model_id": "amazon.titan-embed-text-v2:0",
                          "content_type": "application/json",
                          "request_body": "{\"inputText\": \"${parameters.text}\"}",
                          "response_body": "$.embedding"
                      },
                      "credential": {
                          "roleArn": invoke_role_arn
                      },
                      "actions": [
                          {
                              "action_type": "predict",
                              "method": "POST",
                              "url": f"https://bedrock-runtime.{region}.amazonaws.com/model/${{parameters.model_id}}/invoke",
                              "headers": {
                                  "content-type": "${parameters.content_type}"
                              },
                              "request_body": "${parameters.request_body}",
                              "pre_process_function": "connector.pre_process.bedrock",
                              "post_process_function": "connector.post_process.bedrock"
                          }
                      ]
                  }
                  
                  try:
                      # Create Titan embedding connector
                      response = requests.post(
                          f"{opensearch_endpoint}/_plugins/_ml/connectors/_create",
                          auth=awsauth,
                          json=connector_payload,
                          headers=headers,
                          verify=False
                      )
                      logger.info(f"Register Titan embedding connector response: {response.status_code} - {response.text}")
                      if response.status_code >= 400:
                          raise Exception(f"Failed to register Titan embedding connector: {response.text}")
                      
                      logger.info("Successfully registered Titan embedding connector")
                      
                      embedding_connector_id = json.loads(response.text)['connector_id']
                      
                      if not embedding_connector_id:
                          raise Exception("Could not find Titan embedding connector ID after registration")
                      
                      # Create model from connector
                      model_payload = {
                          "name": "titan-embedding-model",
                          "function_name": "remote",
                          "description": "Titan Embedding model via Amazon Bedrock",
                          "connector_id": embedding_connector_id
                      }
                      
                      response = requests.post(
                          f"{opensearch_endpoint}/_plugins/_ml/models/_register",
                          auth=awsauth,
                          json=model_payload,
                          headers=headers,
                          verify=False
                      )
                      logger.info(f"Register Titan embedding model response: {response.status_code} - {response.text}")
                      
                      embedding_model_id = response.json()['model_id']
                      
                      if not embedding_model_id:
                          raise Exception("Could not find Titan embedding model ID after registration")
                      
                      responseData['embeddingModelId'] = embedding_model_id
                      responseData['embeddingConnectorId'] = embedding_connector_id
                      logger.info(f"Titan embedding model ID: {embedding_model_id}")
                      logger.info(f"Titan embedding connector ID: {embedding_connector_id}")
          
                      
          
                      # Deploy Embedding model
                      response = requests.post(
                          f"{opensearch_endpoint}/_plugins/_ml/models/{embedding_model_id}/_deploy",
                          auth=awsauth,
                          headers=headers,
                          verify=False
                      )
                      logger.info(f"Embedding model deploy response: {response.status_code} - {response.text}")
                      if response.status_code >= 400:
                          raise Exception(f"Failed to deploy Embedding model: {response.text}")
          
          
                  except Exception as e:
                      logger.error(f"Error creating Titan embedding integration: {str(e)}")
                      raise e
                  
                  # 6. Register and deploy DeepSeek Model - Not needed anymore as it's handled by the integration
                  # Directly proceed to importing knowledge base data
                  
                  # 7. Import Knowledge Base Data
                  logger.info("Importing Knowledge Base Data")
                  index_name = "emr_upgrade_hive"
                  
                  # Define the mapping for the index
                  mapping = {
                      "settings": {
                          "index": {
                              "knn": True,
                              "number_of_shards": 1,
                              "number_of_replicas": 1
                          }
                      },
                      "mappings": {
                          "properties": {
                              "text": {"type": "text"},
                              "text_embedding": {
                                  "type": "knn_vector",
                                  "dimension": 1024,  # Titan embedding v2 dimension is 1024
                                  "method": {
                                      "name": "hnsw",
                                      "space_type": "l2",
                                      "engine": "faiss",
                                      "parameters": {"ef_construction": 128, "m": 24}
                                  }
                              }
                          }
                      }
                  }
                  
                  
                  # 9. Create Search Pipeline
                  logger.info("Creating Search Pipeline")
                  search_pipeline_payload = {
                              "response_processors": [
                                {
                                  "retrieval_augmented_generation": {
                                    "tag": "Demo pipeline",
                                    "description": "Demo pipeline Using DeepSeek R1",
                                    "model_id": "SPOgIZcBnlXe1e0nU4po",
                                    "context_field_list": [
                                      "text"
                                    ],
                                    "system_prompt": "你是一个Amazon EMR版本升级助手.",
                                    "user_instructions": "针对给定的问题，用少于 200 个字给出简洁、翔实的答案"
                                  }
                                }
                              ],
                              "phase_results_processors": [
                                {
                                  "normalization-processor": {
                                    "normalization": {
                                      "technique": "min_max"
                                    },
                                    "combination": {
                                      "technique": "arithmetic_mean",
                                      "parameters": {
                                        "weights": [
                                          0.6,
                                          0.4
                                        ]
                                      }
                                    }
                                  }
                                }
                              ]
                          }
                  
                  try:
                      response = requests.put(
                          f"{opensearch_endpoint}/_search/pipeline/my-conversation-search-pipeline-deepseek-zh",
                          auth=awsauth,
                          json=search_pipeline_payload,
                          headers=headers,
                          verify=False
                      )
                      logger.info(f"Search pipeline response: {response.status_code} - {response.text}")
                      if response.status_code >= 400:
                          raise Exception(f"Failed to create Search pipeline: {response.text}")
                  except Exception as e:
                      logger.error(f"Error creating Search pipeline: {str(e)}")
                      raise e
                  
                  logger.info("Sending success response to CloudFormation")
                  send_cfn_response(event, context, SUCCESS, responseData)
                  
                  return {
                      'statusCode': 200,
                      'body': json.dumps({
                          'deepseekConnectorId': deepseek_connector_id,
                          'embeddingConnectorId': embedding_connector_id,
                          'deepseekModelId': deepseek_model_id,
                          'embeddingModelId': embedding_model_id
                      })
                  }
              except Exception as e:
                  error_message = str(e)
                  logger.error(f"Error: {error_message}")
                  send_cfn_response(event, context, FAILED, {"Error": error_message})
                  raise e

  OpenSearchConfigurationCustomResource:
    Type: Custom::OpenSearchConfiguration
    DependsOn:
      - InvokeDeepSeekRole
      - CreateDeepSeekConnectorRole
      - OpenSearchConfigurationLambda
      - InvokeDeepSeekRolePolicy
    Properties:
      ServiceToken: !GetAtt OpenSearchConfigurationLambda.Arn
      Region: !Ref Region
      
  # EC2 Instance Security Group (if not provided)
  AppServerSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Condition: CreateSecurityGroup
    Properties:
      GroupDescription: Security group for RAG application server
      VpcId: !Ref VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
          Description: SSH access
        - IpProtocol: tcp
          FromPort: 5001
          ToPort: 5001
          CidrIp: 0.0.0.0/0
          Description: Application access
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}-app-server-sg"
          
  # IAM Role for EC2 Instance
  AppServerRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
      Policies:
        - PolicyName: OpenSearchAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - es:ESHttpGet
                  - es:ESHttpPost
                  - es:ESHttpPut
                Resource: !Sub 'arn:aws:es:${Region}:${AWS::AccountId}:domain/${OpenSearchDomainName}/*'
        - PolicyName: SecretsManagerAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - secretsmanager:GetSecretValue
                  - secretsmanager:DescribeSecret
                Resource: 
                  - !Sub 'arn:aws:secretsmanager:${Region}:${AWS::AccountId}:secret:${OpenSearchCredentialsSecretName}*'
                
  AppServerInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref AppServerRole
        
  # EC2 Instance for RAG Application
  AppServer:
    Type: AWS::EC2::Instance
    DependsOn: OpenSearchConfigurationCustomResource
    Properties:
      InstanceType: c6i.large
      ImageId: !FindInMap [RegionMap, !Ref "AWS::Region", AMI]
      KeyName: !Ref KeyName
      SecurityGroupIds:
        - !If [CreateSecurityGroup, !Ref AppServerSecurityGroup, !Ref InstanceSecurityGroup]
      SubnetId: !Ref SubnetId
      IamInstanceProfile: !Ref AppServerInstanceProfile
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}-rag-app-server"
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -xe
          
          # Update system packages
          yum update -y
          yum install -y git gcc openssl-devel bzip2-devel libffi-devel zlib-devel wget make
          
          # Install Python 3.13 from source
          cd /opt
          wget https://www.python.org/ftp/python/3.13.0/Python-3.13.0.tgz
          tar xzf Python-3.13.0.tgz
          cd Python-3.13.0
          ./configure --enable-optimizations
          make -j $(nproc)
          make altinstall
          
          # Verify Python 3.13 installation (don't override system Python)
          /usr/local/bin/python3.13 --version
          /usr/local/bin/pip3.13 --version
          
          # Clone the repository
          cd /home/ec2-user
          git clone https://github.com/norrishuang/amazon-emr-upgrade-assistant.git
          chown -R ec2-user:ec2-user amazon-emr-upgrade-assistant
          
          cd amazon-emr-upgrade-assistant
          
          # Set up environment file
          cp qa_app/.env.example qa_app/.env
          
          # Extract OpenSearch host from endpoint URL
          OPENSEARCH_HOST=$(echo "${OpenSearchDomainEndpoint}" | sed -e 's|^https://||' -e 's|^http://||')
          
          # Get OpenSearch credentials from Secrets Manager
          SECRET_VALUE=$(aws secretsmanager get-secret-value --secret-id ${OpenSearchCredentialsSecretName} --region ${AWS::Region} --query SecretString --output text)
          OPENSEARCH_USER=$(echo $SECRET_VALUE | jq -r '.username')
          OPENSEARCH_PASSWORD=$(echo $SECRET_VALUE | jq -r '.password')
          
          # Update environment variables
          sed -i "s/OPENSEARCH_HOST=.*/OPENSEARCH_HOST=$OPENSEARCH_HOST/" qa_app/.env
          sed -i "s/OPENSEARCH_USER=.*/OPENSEARCH_USER=$OPENSEARCH_USER/" qa_app/.env
          sed -i "s/OPENSEARCH_PASSWORD=.*/OPENSEARCH_PASSWORD=$OPENSEARCH_PASSWORD/" qa_app/.env
          sed -i "s/OPENSEARCH_INDEX=.*/OPENSEARCH_INDEX=emr_upgrade_hive/" qa_app/.env
          sed -i "s/OPENSEARCH_EMBEDDING_MODEL_ID=.*/OPENSEARCH_EMBEDDING_MODEL_ID=${OpenSearchConfigurationCustomResource.embeddingModelId}/" qa_app/.env
          sed -i "s/OPENSEARCH_SECRET_NAME=.*/OPENSEARCH_SECRET_NAME=${OpenSearchCredentialsSecretName}/" qa_app/.env
          sed -i "s/AWS_REGION=.*/AWS_REGION=${AWS::Region}/" qa_app/.env
          
          # Install jq if not already installed
          yum install -y jq
          
          # Install dependencies using Python 3.13
          /usr/local/bin/pip3.13 install --upgrade pip
          /usr/local/bin/pip3.13 install -r requirements.txt
          
          # Start the application with Python 3.13
          cd /home/ec2-user/amazon-emr-upgrade-assistant
          nohup /usr/local/bin/python3.13 qa_app/app_conversational.py > app.log 2>&1 &
          
          # Wait a moment to ensure the application has started
          sleep 5
          
          # Signal CloudFormation that the instance is ready (using system Python)
          /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --resource AppServer --region ${AWS::Region}

Outputs:
  InvokeDeepSeekRoleArn:
    Description: ARN of the role used to invoke SageMaker endpoints
    Value: !GetAtt InvokeDeepSeekRole.Arn
    Export:
      Name: !Sub "${AWS::StackName}-InvokeDeepSeekRoleArn"
  
  CreateDeepSeekConnectorRoleArn:
    Description: ARN of the role used to create ML connectors in OpenSearch
    Value: !GetAtt CreateDeepSeekConnectorRole.Arn
    Export:
      Name: !Sub "${AWS::StackName}-CreateDeepSeekConnectorRoleArn"
  
  OpenSearchConfigurationLambdaArn:
    Description: ARN of the Lambda function that configures OpenSearch
    Value: !GetAtt OpenSearchConfigurationLambda.Arn
    Export:
      Name: !Sub "${AWS::StackName}-OpenSearchConfigurationLambdaArn"
  
  DeepSeekConnectorId:
    Description: ID of the DeepSeek Bedrock integration
    Value: !GetAtt OpenSearchConfigurationCustomResource.deepseekConnectorId
  
  EmbeddingConnectorId:
    Description: ID of the Titan Embedding integration
    Value: !GetAtt OpenSearchConfigurationCustomResource.embeddingConnectorId
  
  DeepSeekModelId:
    Description: ID of the DeepSeek Bedrock ML model
    Value: !GetAtt OpenSearchConfigurationCustomResource.deepseekModelId
  
  EmbeddingModelId:
    Description: ID of the Titan Embedding ML model
    Value: !GetAtt OpenSearchConfigurationCustomResource.embeddingModelId
  
  SearchPipelineName:
    Description: Name of the OpenSearch search pipeline created for RAG
    Value: "my-conversation-search-pipeline-deepseek-zh"
    Export:
      Name: !Sub "${AWS::StackName}-SearchPipelineName"
      
  AppServerPublicIP:
    Description: Public IP address of the application server
    Value: !GetAtt AppServer.PublicIp
    
  AppServerPublicDNS:
    Description: Public DNS name of the application server
    Value: !GetAtt AppServer.PublicDnsName
    
  ApplicationURL:
    Description: URL to access the RAG application
    Value: !Sub "http://${AppServer.PublicDnsName}:5001/"
